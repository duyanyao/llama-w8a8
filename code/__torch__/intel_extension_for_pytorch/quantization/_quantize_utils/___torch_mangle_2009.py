class QuantizationDispatchModule(Module):
  __parameters__ = []
  __buffers__ = []
  def forward(self: __torch__.intel_extension_for_pytorch.quantization._quantize_utils.___torch_mangle_2009.QuantizationDispatchModule,
    input_ids: Tensor,
    attention_mask: Tensor,
    position_ids: Tensor,
    past_key_values: Tuple[Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor]]) -> Tuple[Tensor, Tuple[Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor], Tuple[Tensor, Tensor, Tensor, Tensor]]]:
    _0, _1, _2, _3, _4, _5, _6, _7, _8, _9, _10, _11, _12, _13, _14, _15, _16, _17, _18, _19, _20, _21, _22, _23, _24, _25, _26, _27, _28, _29, _30, _31, = past_key_values
    x, x0, x1, x2, = _0
    x3, x4, x5, x6, = _1
    x7, x8, x9, x10, = _2
    x11, x12, x13, x14, = _3
    x15, x16, x17, x18, = _4
    x19, x20, x21, x22, = _5
    x23, x24, x25, x26, = _6
    x27, x28, x29, x30, = _7
    x31, x32, x33, x34, = _8
    x35, x36, x37, x38, = _9
    x39, x40, x41, x42, = _10
    x43, x44, x45, x46, = _11
    x47, x48, x49, x50, = _12
    x51, x52, x53, x54, = _13
    x55, x56, x57, x58, = _14
    x59, x60, x61, x62, = _15
    x63, x64, x65, x66, = _16
    x67, x68, x69, x70, = _17
    x71, x72, x73, x74, = _18
    x75, x76, x77, x78, = _19
    x79, x80, x81, x82, = _20
    x83, x84, x85, x86, = _21
    x87, x88, x89, x90, = _22
    x91, x92, x93, x94, = _23
    x95, x96, x97, x98, = _24
    x99, x100, x101, x102, = _25
    x103, x104, x105, x106, = _26
    x107, x108, x109, x110, = _27
    x111, x112, x113, x114, = _28
    x115, x116, x117, x118, = _29
    x119, x120, x121, x122, = _30
    x123, x124, x125, x126, = _31
    input = torch.alias(input_ids)
    _32 = torch.alias(attention_mask)
    _33 = torch.alias(position_ids)
    _34 = torch.alias(x)
    _35 = torch.alias(x0)
    _36 = torch.alias(x1)
    _37 = torch.alias(x2)
    _38 = torch.alias(x3)
    _39 = torch.alias(x4)
    _40 = torch.alias(x5)
    _41 = torch.alias(x6)
    _42 = torch.alias(x7)
    _43 = torch.alias(x8)
    _44 = torch.alias(x9)
    _45 = torch.alias(x10)
    _46 = torch.alias(x11)
    _47 = torch.alias(x12)
    _48 = torch.alias(x13)
    _49 = torch.alias(x14)
    _50 = torch.alias(x15)
    _51 = torch.alias(x16)
    _52 = torch.alias(x17)
    _53 = torch.alias(x18)
    _54 = torch.alias(x19)
    _55 = torch.alias(x20)
    _56 = torch.alias(x21)
    _57 = torch.alias(x22)
    _58 = torch.alias(x23)
    _59 = torch.alias(x24)
    _60 = torch.alias(x25)
    _61 = torch.alias(x26)
    _62 = torch.alias(x27)
    _63 = torch.alias(x28)
    _64 = torch.alias(x29)
    _65 = torch.alias(x30)
    _66 = torch.alias(x31)
    _67 = torch.alias(x32)
    _68 = torch.alias(x33)
    _69 = torch.alias(x34)
    _70 = torch.alias(x35)
    _71 = torch.alias(x36)
    _72 = torch.alias(x37)
    _73 = torch.alias(x38)
    _74 = torch.alias(x39)
    _75 = torch.alias(x40)
    _76 = torch.alias(x41)
    _77 = torch.alias(x42)
    _78 = torch.alias(x43)
    _79 = torch.alias(x44)
    _80 = torch.alias(x45)
    _81 = torch.alias(x46)
    _82 = torch.alias(x47)
    _83 = torch.alias(x48)
    _84 = torch.alias(x49)
    _85 = torch.alias(x50)
    _86 = torch.alias(x51)
    _87 = torch.alias(x52)
    _88 = torch.alias(x53)
    _89 = torch.alias(x54)
    _90 = torch.alias(x55)
    _91 = torch.alias(x56)
    _92 = torch.alias(x57)
    _93 = torch.alias(x58)
    _94 = torch.alias(x59)
    _95 = torch.alias(x60)
    _96 = torch.alias(x61)
    _97 = torch.alias(x62)
    _98 = torch.alias(x63)
    _99 = torch.alias(x64)
    _100 = torch.alias(x65)
    _101 = torch.alias(x66)
    _102 = torch.alias(x67)
    _103 = torch.alias(x68)
    _104 = torch.alias(x69)
    _105 = torch.alias(x70)
    _106 = torch.alias(x71)
    _107 = torch.alias(x72)
    _108 = torch.alias(x73)
    _109 = torch.alias(x74)
    _110 = torch.alias(x75)
    _111 = torch.alias(x76)
    _112 = torch.alias(x77)
    _113 = torch.alias(x78)
    _114 = torch.alias(x79)
    _115 = torch.alias(x80)
    _116 = torch.alias(x81)
    _117 = torch.alias(x82)
    _118 = torch.alias(x83)
    _119 = torch.alias(x84)
    _120 = torch.alias(x85)
    _121 = torch.alias(x86)
    _122 = torch.alias(x87)
    _123 = torch.alias(x88)
    _124 = torch.alias(x89)
    _125 = torch.alias(x90)
    _126 = torch.alias(x91)
    _127 = torch.alias(x92)
    _128 = torch.alias(x93)
    _129 = torch.alias(x94)
    _130 = torch.alias(x95)
    _131 = torch.alias(x96)
    _132 = torch.alias(x97)
    _133 = torch.alias(x98)
    _134 = torch.alias(x99)
    _135 = torch.alias(x100)
    _136 = torch.alias(x101)
    _137 = torch.alias(x102)
    _138 = torch.alias(x103)
    _139 = torch.alias(x104)
    _140 = torch.alias(x105)
    _141 = torch.alias(x106)
    _142 = torch.alias(x107)
    _143 = torch.alias(x108)
    _144 = torch.alias(x109)
    _145 = torch.alias(x110)
    _146 = torch.alias(x111)
    _147 = torch.alias(x112)
    _148 = torch.alias(x113)
    _149 = torch.alias(x114)
    _150 = torch.alias(x115)
    _151 = torch.alias(x116)
    _152 = torch.alias(x117)
    _153 = torch.alias(x118)
    _154 = torch.alias(x119)
    _155 = torch.alias(x120)
    _156 = torch.alias(x121)
    _157 = torch.alias(x122)
    _158 = torch.alias(x123)
    _159 = torch.alias(x124)
    _160 = torch.alias(x125)
    _161 = torch.alias(x126)
    ret = ops.prim.NumToTensor(torch.size(input, 0))
    ret0 = ops.prim.NumToTensor(torch.size(input, 1))
    bsz = torch.alias(ret)
    _162 = int(bsz)
    tgt_len = torch.alias(ret0)
    _163 = int(tgt_len)
    ret1 = torch.view(_33, [-1, _163])
    _164 = torch.to(torch.alias(ret1), 4)
    ret2 = torch.embedding(CONSTANTS.c0, input, 0)
    _165 = torch.alias(ret2)
    mask = torch.full([_163, _163], -3.4028234663852886e+38, dtype=None, layout=None, device=torch.device("cpu"), pin_memory=False)
    mask_cond = torch.arange(torch.size(mask, -1), dtype=None, layout=None, device=torch.device("cpu"), pin_memory=False)
    _166 = torch.view(torch.add(mask_cond, CONSTANTS.c1), [torch.size(mask, -1), 1])
    mask0 = torch.masked_fill_(mask, torch.lt(mask_cond, _166), 0)
    mask1 = torch.to(mask0, 6)
    _167 = torch.unsqueeze(torch.unsqueeze(mask1, 0), 1)
    _168 = torch.slice(_167, 2, 0, 9223372036854775807)
    _169 = torch.slice(_168, 3, 0, 9223372036854775807)
    ret3 = torch.add(tgt_len, CONSTANTS.c2)
    _170 = [_162, 1, _163, int(torch.alias(ret3))]
    combined_attention_mask = torch.expand(_169, _170)
    ret4 = ops.prim.NumToTensor(torch.size(_32, 0))
    ret5 = ops.prim.NumToTensor(torch.size(_32, 1))
    _171 = int(torch.alias(ret4))
    _172 = int(torch.alias(ret5))
    _173 = torch.slice(_32, 0, 0, 9223372036854775807)
    _174 = torch.unsqueeze(torch.unsqueeze(_173, 1), 2)
    ret6 = torch.slice(_174, 3, 0, 9223372036854775807)
    ret7 = torch.expand(torch.alias(ret6), [_171, 1, _163, _172])
    ret8 = torch.rsub(torch.to(torch.alias(ret7), 6), 1.)
    _175 = torch.alias(ret8)
    ret9 = torch.to(_175, 11)
    ret10 = torch.masked_fill(_175, torch.alias(ret9), -3.4028234663852886e+38)
    expanded_attn_mask = torch.to(torch.alias(ret10), dtype=6, layout=0, device=torch.device("cpu"))
    _176 = torch.to(expanded_attn_mask, torch.device("cpu"), 6, False, True)
    _177 = torch.to(combined_attention_mask, torch.device("cpu"), 6, False, True)
    _178 = torch.add(_176, _177)
    _179 = torch.to(_165, 6)
    ret11 = torch.pow(_179, 2)
    ret12 = torch.mean(torch.alias(ret11), [-1], True)
    ret13 = torch.add(torch.alias(ret12), CONSTANTS.c3)
    ret14 = torch.rsqrt(torch.alias(ret13))
    ret15 = torch.mul(_179, torch.alias(ret14))
    ret16 = torch.mul(CONSTANTS.c4, torch.alias(ret15))
    _180 = torch.alias(ret16)
    ret17 = ops.prim.NumToTensor(torch.size(_180, 0))
    ret18 = ops.prim.NumToTensor(torch.size(_180, 1))
    _181 = int(torch.alias(ret17))
    _182 = int(torch.alias(ret18))
    ret19 = torch.mul(_180, CONSTANTS.c5)
    ret20 = torch.quantize_per_tensor(torch.alias(ret19), 0.014414399862289429, 128, 13)
    ret21 = torch.dequantize(torch.alias(ret20))
    ret22 = torch.linear(torch.alias(ret21), torch.dequantize(CONSTANTS.c6))
    _183 = torch.alias(ret22)
    _184 = [_181, _182, 32, 128]
    ret23 = torch.view(_183, _184)
    _185 = torch.alias(ret23)
    ret24 = torch.mul(_180, CONSTANTS.c5)
    ret25 = torch.quantize_per_tensor(torch.alias(ret24), 0.014414399862289429, 128, 13)
    ret26 = torch.dequantize(torch.alias(ret25))
    ret27 = torch.linear(torch.alias(ret26), torch.dequantize(CONSTANTS.c7))
    ret28 = torch.view(torch.alias(ret27), _184)
    _186 = torch.alias(ret28)
    ret29 = torch.mul(_180, CONSTANTS.c5)
    ret30 = torch.quantize_per_tensor(torch.alias(ret29), 0.014414399862289429, 128, 13)
    ret31 = torch.dequantize(torch.alias(ret30))
    ret32 = torch.linear(torch.alias(ret31), torch.dequantize(CONSTANTS.c8))
    ret33 = torch.view(torch.alias(ret32), _184)
    _187 = torch.alias(ret33)
    _188 = torch.contiguous(_164)
    _189 = torch.contiguous(_186)
    _190 = torch.contiguous(_185)
    ops.torch_ipex.rotary_position_embedding(_189, CONSTANTS.c9, _188, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_190, CONSTANTS.c9, _188, 32, 128, 64, 128)
    _191 = torch.contiguous(_34)
    _192 = torch.contiguous(_35)
    _193 = torch.contiguous(_36)
    _194 = torch.contiguous(_37)
    ret34 = torch.select(_194, 0, 0)
    ret35, ret36, ret37, ret38, ret39 = ops.torch_ipex.masked_multihead_self_attention(_190, _189, _187, _191, _192, _193, torch.alias(ret34), 11.313708498984761, 64, None, _178)
    _195 = torch.alias(ret35)
    _196 = torch.alias(ret37)
    _197 = torch.alias(ret38)
    _198 = torch.alias(ret39)
    ret40 = ops.prim.NumToTensor(torch.size(_190, 1))
    ret41 = torch.add(_194, torch.alias(ret40))
    _199 = torch.to(torch.alias(ret41), torch.device("cpu"), 4, False, True)
    ret42 = torch.transpose(_195, 1, 2)
    ret43 = torch.reshape(torch.alias(ret42), [_181, _182, 4096])
    ret44 = torch.mul(torch.alias(ret43), CONSTANTS.c10)
    ret45 = torch.quantize_per_tensor(torch.alias(ret44), 0.0043197330087423325, 115, 13)
    ret46 = torch.dequantize(torch.alias(ret45))
    ret47 = torch.linear(torch.alias(ret46), torch.dequantize(CONSTANTS.c11))
    ret48 = torch.add(_179, torch.alias(ret47))
    _200 = torch.to(torch.alias(ret48), 6)
    ret49 = torch.pow(_200, 2)
    ret50 = torch.mean(torch.alias(ret49), [-1], True)
    ret51 = torch.add(torch.alias(ret50), CONSTANTS.c3)
    ret52 = torch.rsqrt(torch.alias(ret51))
    ret53 = torch.mul(_200, torch.alias(ret52))
    ret54 = torch.mul(CONSTANTS.c12, torch.alias(ret53))
    _201 = torch.alias(ret54)
    ret55 = torch.mul(_201, CONSTANTS.c13)
    ret56 = torch.quantize_per_tensor(torch.alias(ret55), 0.010426418855786324, 158, 13)
    ret57 = torch.dequantize(torch.alias(ret56))
    ret58 = torch.linear(torch.alias(ret57), torch.dequantize(CONSTANTS.c14))
    input0 = torch.alias(ret58)
    ret59 = torch.silu(input0)
    _202 = torch.alias(ret59)
    ret60 = torch.mul(_201, CONSTANTS.c13)
    ret61 = torch.quantize_per_tensor(torch.alias(ret60), 0.010426418855786324, 158, 13)
    ret62 = torch.dequantize(torch.alias(ret61))
    ret63 = torch.linear(torch.alias(ret62), torch.dequantize(CONSTANTS.c15))
    ret64 = torch.mul(_202, torch.alias(ret63))
    ret65 = torch.mul(torch.alias(ret64), CONSTANTS.c16)
    ret66 = torch.quantize_per_tensor(torch.alias(ret65), 0.0070060542784631252, 143, 13)
    ret67 = torch.dequantize(torch.alias(ret66))
    ret68 = torch.linear(torch.alias(ret67), torch.dequantize(CONSTANTS.c17))
    ret69 = torch.add(_200, torch.alias(ret68))
    _203 = torch.to(torch.alias(ret69), 6)
    ret70 = torch.pow(_203, 2)
    ret71 = torch.mean(torch.alias(ret70), [-1], True)
    ret72 = torch.add(torch.alias(ret71), CONSTANTS.c3)
    ret73 = torch.rsqrt(torch.alias(ret72))
    ret74 = torch.mul(_203, torch.alias(ret73))
    ret75 = torch.mul(CONSTANTS.c18, torch.alias(ret74))
    _204 = torch.alias(ret75)
    ret76 = ops.prim.NumToTensor(torch.size(_204, 0))
    ret77 = ops.prim.NumToTensor(torch.size(_204, 1))
    _205 = int(torch.alias(ret76))
    _206 = int(torch.alias(ret77))
    ret78 = torch.mul(_204, CONSTANTS.c19)
    ret79 = torch.quantize_per_tensor(torch.alias(ret78), 0.014595780521631241, 101, 13)
    ret80 = torch.dequantize(torch.alias(ret79))
    ret81 = torch.linear(torch.alias(ret80), torch.dequantize(CONSTANTS.c20))
    _207 = torch.alias(ret81)
    _208 = [_205, _206, 32, 128]
    ret82 = torch.view(_207, _208)
    _209 = torch.alias(ret82)
    ret83 = torch.mul(_204, CONSTANTS.c19)
    ret84 = torch.quantize_per_tensor(torch.alias(ret83), 0.014595780521631241, 101, 13)
    ret85 = torch.dequantize(torch.alias(ret84))
    ret86 = torch.linear(torch.alias(ret85), torch.dequantize(CONSTANTS.c21))
    ret87 = torch.view(torch.alias(ret86), _208)
    _210 = torch.alias(ret87)
    ret88 = torch.mul(_204, CONSTANTS.c19)
    ret89 = torch.quantize_per_tensor(torch.alias(ret88), 0.014595780521631241, 101, 13)
    ret90 = torch.dequantize(torch.alias(ret89))
    ret91 = torch.linear(torch.alias(ret90), torch.dequantize(CONSTANTS.c22))
    ret92 = torch.view(torch.alias(ret91), _208)
    _211 = torch.alias(ret92)
    _212 = torch.contiguous(_188)
    _213 = torch.contiguous(_210)
    _214 = torch.contiguous(_209)
    ops.torch_ipex.rotary_position_embedding(_213, CONSTANTS.c9, _212, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_214, CONSTANTS.c9, _212, 32, 128, 64, 128)
    _215 = torch.contiguous(_38)
    _216 = torch.contiguous(_39)
    _217 = torch.contiguous(_40)
    _218 = torch.contiguous(_41)
    ret93 = torch.select(_218, 0, 0)
    ret94, ret95, ret96, ret97, ret98 = ops.torch_ipex.masked_multihead_self_attention(_214, _213, _211, _215, _216, _217, torch.alias(ret93), 11.313708498984761, 64, None, _178)
    _219 = torch.alias(ret94)
    _220 = torch.alias(ret96)
    _221 = torch.alias(ret97)
    _222 = torch.alias(ret98)
    ret99 = ops.prim.NumToTensor(torch.size(_214, 1))
    ret100 = torch.add(_218, torch.alias(ret99))
    _223 = torch.to(torch.alias(ret100), torch.device("cpu"), 4, False, True)
    ret101 = torch.transpose(_219, 1, 2)
    ret102 = torch.reshape(torch.alias(ret101), [_205, _206, 4096])
    ret103 = torch.mul(torch.alias(ret102), CONSTANTS.c23)
    ret104 = torch.quantize_per_tensor(torch.alias(ret103), 0.0039414265193045139, 119, 13)
    ret105 = torch.dequantize(torch.alias(ret104))
    ret106 = torch.linear(torch.alias(ret105), torch.dequantize(CONSTANTS.c24))
    ret107 = torch.add(_203, torch.alias(ret106))
    _224 = torch.to(torch.alias(ret107), 6)
    ret108 = torch.pow(_224, 2)
    ret109 = torch.mean(torch.alias(ret108), [-1], True)
    ret110 = torch.add(torch.alias(ret109), CONSTANTS.c3)
    ret111 = torch.rsqrt(torch.alias(ret110))
    ret112 = torch.mul(_224, torch.alias(ret111))
    ret113 = torch.mul(CONSTANTS.c25, torch.alias(ret112))
    _225 = torch.alias(ret113)
    ret114 = torch.mul(_225, CONSTANTS.c26)
    ret115 = torch.quantize_per_tensor(torch.alias(ret114), 0.0071564735844731331, 120, 13)
    ret116 = torch.dequantize(torch.alias(ret115))
    ret117 = torch.linear(torch.alias(ret116), torch.dequantize(CONSTANTS.c27))
    input1 = torch.alias(ret117)
    ret118 = torch.silu(input1)
    _226 = torch.alias(ret118)
    ret119 = torch.mul(_225, CONSTANTS.c26)
    ret120 = torch.quantize_per_tensor(torch.alias(ret119), 0.0071564735844731331, 120, 13)
    ret121 = torch.dequantize(torch.alias(ret120))
    ret122 = torch.linear(torch.alias(ret121), torch.dequantize(CONSTANTS.c28))
    ret123 = torch.mul(_226, torch.alias(ret122))
    ret124 = torch.mul(torch.alias(ret123), CONSTANTS.c29)
    ret125 = torch.quantize_per_tensor(torch.alias(ret124), 0.25845864415168762, 64, 13)
    ret126 = torch.dequantize(torch.alias(ret125))
    ret127 = torch.linear(torch.alias(ret126), torch.dequantize(CONSTANTS.c30))
    ret128 = torch.add(_224, torch.alias(ret127))
    _227 = torch.to(torch.alias(ret128), 6)
    ret129 = torch.pow(_227, 2)
    ret130 = torch.mean(torch.alias(ret129), [-1], True)
    ret131 = torch.add(torch.alias(ret130), CONSTANTS.c3)
    ret132 = torch.rsqrt(torch.alias(ret131))
    ret133 = torch.mul(_227, torch.alias(ret132))
    ret134 = torch.mul(CONSTANTS.c31, torch.alias(ret133))
    _228 = torch.alias(ret134)
    ret135 = ops.prim.NumToTensor(torch.size(_228, 0))
    ret136 = ops.prim.NumToTensor(torch.size(_228, 1))
    _229 = int(torch.alias(ret135))
    _230 = int(torch.alias(ret136))
    ret137 = torch.mul(_228, CONSTANTS.c32)
    ret138 = torch.quantize_per_tensor(torch.alias(ret137), 0.011059467680752277, 118, 13)
    ret139 = torch.dequantize(torch.alias(ret138))
    ret140 = torch.linear(torch.alias(ret139), torch.dequantize(CONSTANTS.c33))
    _231 = torch.alias(ret140)
    _232 = [_229, _230, 32, 128]
    ret141 = torch.view(_231, _232)
    _233 = torch.alias(ret141)
    ret142 = torch.mul(_228, CONSTANTS.c32)
    ret143 = torch.quantize_per_tensor(torch.alias(ret142), 0.011059467680752277, 118, 13)
    ret144 = torch.dequantize(torch.alias(ret143))
    ret145 = torch.linear(torch.alias(ret144), torch.dequantize(CONSTANTS.c34))
    ret146 = torch.view(torch.alias(ret145), _232)
    _234 = torch.alias(ret146)
    ret147 = torch.mul(_228, CONSTANTS.c32)
    ret148 = torch.quantize_per_tensor(torch.alias(ret147), 0.011059467680752277, 118, 13)
    ret149 = torch.dequantize(torch.alias(ret148))
    ret150 = torch.linear(torch.alias(ret149), torch.dequantize(CONSTANTS.c35))
    ret151 = torch.view(torch.alias(ret150), _232)
    _235 = torch.alias(ret151)
    _236 = torch.contiguous(_212)
    _237 = torch.contiguous(_234)
    _238 = torch.contiguous(_233)
    ops.torch_ipex.rotary_position_embedding(_237, CONSTANTS.c9, _236, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_238, CONSTANTS.c9, _236, 32, 128, 64, 128)
    _239 = torch.contiguous(_42)
    _240 = torch.contiguous(_43)
    _241 = torch.contiguous(_44)
    _242 = torch.contiguous(_45)
    ret152 = torch.select(_242, 0, 0)
    ret153, ret154, ret155, ret156, ret157 = ops.torch_ipex.masked_multihead_self_attention(_238, _237, _235, _239, _240, _241, torch.alias(ret152), 11.313708498984761, 64, None, _178)
    _243 = torch.alias(ret153)
    _244 = torch.alias(ret155)
    _245 = torch.alias(ret156)
    _246 = torch.alias(ret157)
    ret158 = ops.prim.NumToTensor(torch.size(_238, 1))
    ret159 = torch.add(_242, torch.alias(ret158))
    _247 = torch.to(torch.alias(ret159), torch.device("cpu"), 4, False, True)
    ret160 = torch.transpose(_243, 1, 2)
    ret161 = torch.reshape(torch.alias(ret160), [_229, _230, 4096])
    ret162 = torch.mul(torch.alias(ret161), CONSTANTS.c36)
    ret163 = torch.quantize_per_tensor(torch.alias(ret162), 0.004496423527598381, 114, 13)
    ret164 = torch.dequantize(torch.alias(ret163))
    ret165 = torch.linear(torch.alias(ret164), torch.dequantize(CONSTANTS.c37))
    ret166 = torch.add(_227, torch.alias(ret165))
    _248 = torch.to(torch.alias(ret166), 6)
    ret167 = torch.pow(_248, 2)
    ret168 = torch.mean(torch.alias(ret167), [-1], True)
    ret169 = torch.add(torch.alias(ret168), CONSTANTS.c3)
    ret170 = torch.rsqrt(torch.alias(ret169))
    ret171 = torch.mul(_248, torch.alias(ret170))
    ret172 = torch.mul(CONSTANTS.c38, torch.alias(ret171))
    _249 = torch.alias(ret172)
    ret173 = torch.mul(_249, CONSTANTS.c39)
    ret174 = torch.quantize_per_tensor(torch.alias(ret173), 0.0081996433436870575, 117, 13)
    ret175 = torch.dequantize(torch.alias(ret174))
    ret176 = torch.linear(torch.alias(ret175), torch.dequantize(CONSTANTS.c40))
    input2 = torch.alias(ret176)
    ret177 = torch.silu(input2)
    _250 = torch.alias(ret177)
    ret178 = torch.mul(_249, CONSTANTS.c39)
    ret179 = torch.quantize_per_tensor(torch.alias(ret178), 0.0081996433436870575, 117, 13)
    ret180 = torch.dequantize(torch.alias(ret179))
    ret181 = torch.linear(torch.alias(ret180), torch.dequantize(CONSTANTS.c41))
    ret182 = torch.mul(_250, torch.alias(ret181))
    ret183 = torch.mul(torch.alias(ret182), CONSTANTS.c42)
    ret184 = torch.quantize_per_tensor(torch.alias(ret183), 0.010103254579007626, 53, 13)
    ret185 = torch.dequantize(torch.alias(ret184))
    ret186 = torch.linear(torch.alias(ret185), torch.dequantize(CONSTANTS.c43))
    ret187 = torch.add(_248, torch.alias(ret186))
    _251 = torch.to(torch.alias(ret187), 6)
    ret188 = torch.pow(_251, 2)
    ret189 = torch.mean(torch.alias(ret188), [-1], True)
    ret190 = torch.add(torch.alias(ret189), CONSTANTS.c3)
    ret191 = torch.rsqrt(torch.alias(ret190))
    ret192 = torch.mul(_251, torch.alias(ret191))
    ret193 = torch.mul(CONSTANTS.c44, torch.alias(ret192))
    _252 = torch.alias(ret193)
    ret194 = ops.prim.NumToTensor(torch.size(_252, 0))
    ret195 = ops.prim.NumToTensor(torch.size(_252, 1))
    _253 = int(torch.alias(ret194))
    _254 = int(torch.alias(ret195))
    ret196 = torch.mul(_252, CONSTANTS.c45)
    ret197 = torch.quantize_per_tensor(torch.alias(ret196), 0.012151537463068962, 127, 13)
    ret198 = torch.dequantize(torch.alias(ret197))
    ret199 = torch.linear(torch.alias(ret198), torch.dequantize(CONSTANTS.c46))
    _255 = torch.alias(ret199)
    _256 = [_253, _254, 32, 128]
    ret200 = torch.view(_255, _256)
    _257 = torch.alias(ret200)
    ret201 = torch.mul(_252, CONSTANTS.c45)
    ret202 = torch.quantize_per_tensor(torch.alias(ret201), 0.012151537463068962, 127, 13)
    ret203 = torch.dequantize(torch.alias(ret202))
    ret204 = torch.linear(torch.alias(ret203), torch.dequantize(CONSTANTS.c47))
    ret205 = torch.view(torch.alias(ret204), _256)
    _258 = torch.alias(ret205)
    ret206 = torch.mul(_252, CONSTANTS.c45)
    ret207 = torch.quantize_per_tensor(torch.alias(ret206), 0.012151537463068962, 127, 13)
    ret208 = torch.dequantize(torch.alias(ret207))
    ret209 = torch.linear(torch.alias(ret208), torch.dequantize(CONSTANTS.c48))
    ret210 = torch.view(torch.alias(ret209), _256)
    _259 = torch.alias(ret210)
    _260 = torch.contiguous(_236)
    _261 = torch.contiguous(_258)
    _262 = torch.contiguous(_257)
    ops.torch_ipex.rotary_position_embedding(_261, CONSTANTS.c9, _260, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_262, CONSTANTS.c9, _260, 32, 128, 64, 128)
    _263 = torch.contiguous(_46)
    _264 = torch.contiguous(_47)
    _265 = torch.contiguous(_48)
    _266 = torch.contiguous(_49)
    ret211 = torch.select(_266, 0, 0)
    ret212, ret213, ret214, ret215, ret216 = ops.torch_ipex.masked_multihead_self_attention(_262, _261, _259, _263, _264, _265, torch.alias(ret211), 11.313708498984761, 64, None, _178)
    _267 = torch.alias(ret212)
    _268 = torch.alias(ret214)
    _269 = torch.alias(ret215)
    _270 = torch.alias(ret216)
    ret217 = ops.prim.NumToTensor(torch.size(_262, 1))
    ret218 = torch.add(_266, torch.alias(ret217))
    _271 = torch.to(torch.alias(ret218), torch.device("cpu"), 4, False, True)
    ret219 = torch.transpose(_267, 1, 2)
    ret220 = torch.reshape(torch.alias(ret219), [_253, _254, 4096])
    ret221 = torch.mul(torch.alias(ret220), CONSTANTS.c49)
    ret222 = torch.quantize_per_tensor(torch.alias(ret221), 0.0044196108356118202, 120, 13)
    ret223 = torch.dequantize(torch.alias(ret222))
    ret224 = torch.linear(torch.alias(ret223), torch.dequantize(CONSTANTS.c50))
    ret225 = torch.add(_251, torch.alias(ret224))
    _272 = torch.to(torch.alias(ret225), 6)
    ret226 = torch.pow(_272, 2)
    ret227 = torch.mean(torch.alias(ret226), [-1], True)
    ret228 = torch.add(torch.alias(ret227), CONSTANTS.c3)
    ret229 = torch.rsqrt(torch.alias(ret228))
    ret230 = torch.mul(_272, torch.alias(ret229))
    ret231 = torch.mul(CONSTANTS.c51, torch.alias(ret230))
    _273 = torch.alias(ret231)
    ret232 = torch.mul(_273, CONSTANTS.c52)
    ret233 = torch.quantize_per_tensor(torch.alias(ret232), 0.005733058787882328, 132, 13)
    ret234 = torch.dequantize(torch.alias(ret233))
    ret235 = torch.linear(torch.alias(ret234), torch.dequantize(CONSTANTS.c53))
    input3 = torch.alias(ret235)
    ret236 = torch.silu(input3)
    _274 = torch.alias(ret236)
    ret237 = torch.mul(_273, CONSTANTS.c52)
    ret238 = torch.quantize_per_tensor(torch.alias(ret237), 0.005733058787882328, 132, 13)
    ret239 = torch.dequantize(torch.alias(ret238))
    ret240 = torch.linear(torch.alias(ret239), torch.dequantize(CONSTANTS.c54))
    ret241 = torch.mul(_274, torch.alias(ret240))
    ret242 = torch.mul(torch.alias(ret241), CONSTANTS.c55)
    ret243 = torch.quantize_per_tensor(torch.alias(ret242), 0.0072095701470971107, 76, 13)
    ret244 = torch.dequantize(torch.alias(ret243))
    ret245 = torch.linear(torch.alias(ret244), torch.dequantize(CONSTANTS.c56))
    ret246 = torch.add(_272, torch.alias(ret245))
    _275 = torch.to(torch.alias(ret246), 6)
    ret247 = torch.pow(_275, 2)
    ret248 = torch.mean(torch.alias(ret247), [-1], True)
    ret249 = torch.add(torch.alias(ret248), CONSTANTS.c3)
    ret250 = torch.rsqrt(torch.alias(ret249))
    ret251 = torch.mul(_275, torch.alias(ret250))
    ret252 = torch.mul(CONSTANTS.c57, torch.alias(ret251))
    _276 = torch.alias(ret252)
    ret253 = ops.prim.NumToTensor(torch.size(_276, 0))
    ret254 = ops.prim.NumToTensor(torch.size(_276, 1))
    _277 = int(torch.alias(ret253))
    _278 = int(torch.alias(ret254))
    ret255 = torch.mul(_276, CONSTANTS.c58)
    ret256 = torch.quantize_per_tensor(torch.alias(ret255), 0.011181366629898548, 133, 13)
    ret257 = torch.dequantize(torch.alias(ret256))
    ret258 = torch.linear(torch.alias(ret257), torch.dequantize(CONSTANTS.c59))
    _279 = torch.alias(ret258)
    _280 = [_277, _278, 32, 128]
    ret259 = torch.view(_279, _280)
    _281 = torch.alias(ret259)
    ret260 = torch.mul(_276, CONSTANTS.c58)
    ret261 = torch.quantize_per_tensor(torch.alias(ret260), 0.011181366629898548, 133, 13)
    ret262 = torch.dequantize(torch.alias(ret261))
    ret263 = torch.linear(torch.alias(ret262), torch.dequantize(CONSTANTS.c60))
    ret264 = torch.view(torch.alias(ret263), _280)
    _282 = torch.alias(ret264)
    ret265 = torch.mul(_276, CONSTANTS.c58)
    ret266 = torch.quantize_per_tensor(torch.alias(ret265), 0.011181366629898548, 133, 13)
    ret267 = torch.dequantize(torch.alias(ret266))
    ret268 = torch.linear(torch.alias(ret267), torch.dequantize(CONSTANTS.c61))
    ret269 = torch.view(torch.alias(ret268), _280)
    _283 = torch.alias(ret269)
    _284 = torch.contiguous(_260)
    _285 = torch.contiguous(_282)
    _286 = torch.contiguous(_281)
    ops.torch_ipex.rotary_position_embedding(_285, CONSTANTS.c9, _284, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_286, CONSTANTS.c9, _284, 32, 128, 64, 128)
    _287 = torch.contiguous(_50)
    _288 = torch.contiguous(_51)
    _289 = torch.contiguous(_52)
    _290 = torch.contiguous(_53)
    ret270 = torch.select(_290, 0, 0)
    ret271, ret272, ret273, ret274, ret275 = ops.torch_ipex.masked_multihead_self_attention(_286, _285, _283, _287, _288, _289, torch.alias(ret270), 11.313708498984761, 64, None, _178)
    _291 = torch.alias(ret271)
    _292 = torch.alias(ret273)
    _293 = torch.alias(ret274)
    _294 = torch.alias(ret275)
    ret276 = ops.prim.NumToTensor(torch.size(_286, 1))
    ret277 = torch.add(_290, torch.alias(ret276))
    _295 = torch.to(torch.alias(ret277), torch.device("cpu"), 4, False, True)
    ret278 = torch.transpose(_291, 1, 2)
    ret279 = torch.reshape(torch.alias(ret278), [_277, _278, 4096])
    ret280 = torch.mul(torch.alias(ret279), CONSTANTS.c62)
    ret281 = torch.quantize_per_tensor(torch.alias(ret280), 0.0049410923384130001, 131, 13)
    ret282 = torch.dequantize(torch.alias(ret281))
    ret283 = torch.linear(torch.alias(ret282), torch.dequantize(CONSTANTS.c63))
    ret284 = torch.add(_275, torch.alias(ret283))
    _296 = torch.to(torch.alias(ret284), 6)
    ret285 = torch.pow(_296, 2)
    ret286 = torch.mean(torch.alias(ret285), [-1], True)
    ret287 = torch.add(torch.alias(ret286), CONSTANTS.c3)
    ret288 = torch.rsqrt(torch.alias(ret287))
    ret289 = torch.mul(_296, torch.alias(ret288))
    ret290 = torch.mul(CONSTANTS.c64, torch.alias(ret289))
    _297 = torch.alias(ret290)
    ret291 = torch.mul(_297, CONSTANTS.c65)
    ret292 = torch.quantize_per_tensor(torch.alias(ret291), 0.011005217209458351, 121, 13)
    ret293 = torch.dequantize(torch.alias(ret292))
    ret294 = torch.linear(torch.alias(ret293), torch.dequantize(CONSTANTS.c66))
    input4 = torch.alias(ret294)
    ret295 = torch.silu(input4)
    _298 = torch.alias(ret295)
    ret296 = torch.mul(_297, CONSTANTS.c65)
    ret297 = torch.quantize_per_tensor(torch.alias(ret296), 0.011005217209458351, 121, 13)
    ret298 = torch.dequantize(torch.alias(ret297))
    ret299 = torch.linear(torch.alias(ret298), torch.dequantize(CONSTANTS.c67))
    ret300 = torch.mul(_298, torch.alias(ret299))
    ret301 = torch.mul(torch.alias(ret300), CONSTANTS.c68)
    ret302 = torch.quantize_per_tensor(torch.alias(ret301), 0.016467157751321793, 121, 13)
    ret303 = torch.dequantize(torch.alias(ret302))
    ret304 = torch.linear(torch.alias(ret303), torch.dequantize(CONSTANTS.c69))
    ret305 = torch.add(_296, torch.alias(ret304))
    _299 = torch.to(torch.alias(ret305), 6)
    ret306 = torch.pow(_299, 2)
    ret307 = torch.mean(torch.alias(ret306), [-1], True)
    ret308 = torch.add(torch.alias(ret307), CONSTANTS.c3)
    ret309 = torch.rsqrt(torch.alias(ret308))
    ret310 = torch.mul(_299, torch.alias(ret309))
    ret311 = torch.mul(CONSTANTS.c70, torch.alias(ret310))
    _300 = torch.alias(ret311)
    ret312 = ops.prim.NumToTensor(torch.size(_300, 0))
    ret313 = ops.prim.NumToTensor(torch.size(_300, 1))
    _301 = int(torch.alias(ret312))
    _302 = int(torch.alias(ret313))
    ret314 = torch.mul(_300, CONSTANTS.c71)
    ret315 = torch.quantize_per_tensor(torch.alias(ret314), 0.012153234332799911, 118, 13)
    ret316 = torch.dequantize(torch.alias(ret315))
    ret317 = torch.linear(torch.alias(ret316), torch.dequantize(CONSTANTS.c72))
    _303 = torch.alias(ret317)
    _304 = [_301, _302, 32, 128]
    ret318 = torch.view(_303, _304)
    _305 = torch.alias(ret318)
    ret319 = torch.mul(_300, CONSTANTS.c71)
    ret320 = torch.quantize_per_tensor(torch.alias(ret319), 0.012153234332799911, 118, 13)
    ret321 = torch.dequantize(torch.alias(ret320))
    ret322 = torch.linear(torch.alias(ret321), torch.dequantize(CONSTANTS.c73))
    ret323 = torch.view(torch.alias(ret322), _304)
    _306 = torch.alias(ret323)
    ret324 = torch.mul(_300, CONSTANTS.c71)
    ret325 = torch.quantize_per_tensor(torch.alias(ret324), 0.012153234332799911, 118, 13)
    ret326 = torch.dequantize(torch.alias(ret325))
    ret327 = torch.linear(torch.alias(ret326), torch.dequantize(CONSTANTS.c74))
    ret328 = torch.view(torch.alias(ret327), _304)
    _307 = torch.alias(ret328)
    _308 = torch.contiguous(_284)
    _309 = torch.contiguous(_306)
    _310 = torch.contiguous(_305)
    ops.torch_ipex.rotary_position_embedding(_309, CONSTANTS.c9, _308, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_310, CONSTANTS.c9, _308, 32, 128, 64, 128)
    _311 = torch.contiguous(_54)
    _312 = torch.contiguous(_55)
    _313 = torch.contiguous(_56)
    _314 = torch.contiguous(_57)
    ret329 = torch.select(_314, 0, 0)
    ret330, ret331, ret332, ret333, ret334 = ops.torch_ipex.masked_multihead_self_attention(_310, _309, _307, _311, _312, _313, torch.alias(ret329), 11.313708498984761, 64, None, _178)
    _315 = torch.alias(ret330)
    _316 = torch.alias(ret332)
    _317 = torch.alias(ret333)
    _318 = torch.alias(ret334)
    ret335 = ops.prim.NumToTensor(torch.size(_310, 1))
    ret336 = torch.add(_314, torch.alias(ret335))
    _319 = torch.to(torch.alias(ret336), torch.device("cpu"), 4, False, True)
    ret337 = torch.transpose(_315, 1, 2)
    ret338 = torch.reshape(torch.alias(ret337), [_301, _302, 4096])
    ret339 = torch.mul(torch.alias(ret338), CONSTANTS.c75)
    ret340 = torch.quantize_per_tensor(torch.alias(ret339), 0.0044824299402534962, 129, 13)
    ret341 = torch.dequantize(torch.alias(ret340))
    ret342 = torch.linear(torch.alias(ret341), torch.dequantize(CONSTANTS.c76))
    ret343 = torch.add(_299, torch.alias(ret342))
    _320 = torch.to(torch.alias(ret343), 6)
    ret344 = torch.pow(_320, 2)
    ret345 = torch.mean(torch.alias(ret344), [-1], True)
    ret346 = torch.add(torch.alias(ret345), CONSTANTS.c3)
    ret347 = torch.rsqrt(torch.alias(ret346))
    ret348 = torch.mul(_320, torch.alias(ret347))
    ret349 = torch.mul(CONSTANTS.c77, torch.alias(ret348))
    _321 = torch.alias(ret349)
    ret350 = torch.mul(_321, CONSTANTS.c78)
    ret351 = torch.quantize_per_tensor(torch.alias(ret350), 0.0074075614102184772, 137, 13)
    ret352 = torch.dequantize(torch.alias(ret351))
    ret353 = torch.linear(torch.alias(ret352), torch.dequantize(CONSTANTS.c79))
    input5 = torch.alias(ret353)
    ret354 = torch.silu(input5)
    _322 = torch.alias(ret354)
    ret355 = torch.mul(_321, CONSTANTS.c78)
    ret356 = torch.quantize_per_tensor(torch.alias(ret355), 0.0074075614102184772, 137, 13)
    ret357 = torch.dequantize(torch.alias(ret356))
    ret358 = torch.linear(torch.alias(ret357), torch.dequantize(CONSTANTS.c80))
    ret359 = torch.mul(_322, torch.alias(ret358))
    ret360 = torch.mul(torch.alias(ret359), CONSTANTS.c81)
    ret361 = torch.quantize_per_tensor(torch.alias(ret360), 0.0071386187337338924, 176, 13)
    ret362 = torch.dequantize(torch.alias(ret361))
    ret363 = torch.linear(torch.alias(ret362), torch.dequantize(CONSTANTS.c82))
    ret364 = torch.add(_320, torch.alias(ret363))
    _323 = torch.to(torch.alias(ret364), 6)
    ret365 = torch.pow(_323, 2)
    ret366 = torch.mean(torch.alias(ret365), [-1], True)
    ret367 = torch.add(torch.alias(ret366), CONSTANTS.c3)
    ret368 = torch.rsqrt(torch.alias(ret367))
    ret369 = torch.mul(_323, torch.alias(ret368))
    ret370 = torch.mul(CONSTANTS.c83, torch.alias(ret369))
    _324 = torch.alias(ret370)
    ret371 = ops.prim.NumToTensor(torch.size(_324, 0))
    ret372 = ops.prim.NumToTensor(torch.size(_324, 1))
    _325 = int(torch.alias(ret371))
    _326 = int(torch.alias(ret372))
    ret373 = torch.mul(_324, CONSTANTS.c84)
    ret374 = torch.quantize_per_tensor(torch.alias(ret373), 0.012754869647324085, 126, 13)
    ret375 = torch.dequantize(torch.alias(ret374))
    ret376 = torch.linear(torch.alias(ret375), torch.dequantize(CONSTANTS.c85))
    _327 = torch.alias(ret376)
    _328 = [_325, _326, 32, 128]
    ret377 = torch.view(_327, _328)
    _329 = torch.alias(ret377)
    ret378 = torch.mul(_324, CONSTANTS.c84)
    ret379 = torch.quantize_per_tensor(torch.alias(ret378), 0.012754869647324085, 126, 13)
    ret380 = torch.dequantize(torch.alias(ret379))
    ret381 = torch.linear(torch.alias(ret380), torch.dequantize(CONSTANTS.c86))
    ret382 = torch.view(torch.alias(ret381), _328)
    _330 = torch.alias(ret382)
    ret383 = torch.mul(_324, CONSTANTS.c84)
    ret384 = torch.quantize_per_tensor(torch.alias(ret383), 0.012754869647324085, 126, 13)
    ret385 = torch.dequantize(torch.alias(ret384))
    ret386 = torch.linear(torch.alias(ret385), torch.dequantize(CONSTANTS.c87))
    ret387 = torch.view(torch.alias(ret386), _328)
    _331 = torch.alias(ret387)
    _332 = torch.contiguous(_308)
    _333 = torch.contiguous(_330)
    _334 = torch.contiguous(_329)
    ops.torch_ipex.rotary_position_embedding(_333, CONSTANTS.c9, _332, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_334, CONSTANTS.c9, _332, 32, 128, 64, 128)
    _335 = torch.contiguous(_58)
    _336 = torch.contiguous(_59)
    _337 = torch.contiguous(_60)
    _338 = torch.contiguous(_61)
    ret388 = torch.select(_338, 0, 0)
    ret389, ret390, ret391, ret392, ret393 = ops.torch_ipex.masked_multihead_self_attention(_334, _333, _331, _335, _336, _337, torch.alias(ret388), 11.313708498984761, 64, None, _178)
    _339 = torch.alias(ret389)
    _340 = torch.alias(ret391)
    _341 = torch.alias(ret392)
    _342 = torch.alias(ret393)
    ret394 = ops.prim.NumToTensor(torch.size(_334, 1))
    ret395 = torch.add(_338, torch.alias(ret394))
    _343 = torch.to(torch.alias(ret395), torch.device("cpu"), 4, False, True)
    ret396 = torch.transpose(_339, 1, 2)
    ret397 = torch.reshape(torch.alias(ret396), [_325, _326, 4096])
    ret398 = torch.mul(torch.alias(ret397), CONSTANTS.c88)
    ret399 = torch.quantize_per_tensor(torch.alias(ret398), 0.0068635530769824982, 135, 13)
    ret400 = torch.dequantize(torch.alias(ret399))
    ret401 = torch.linear(torch.alias(ret400), torch.dequantize(CONSTANTS.c89))
    ret402 = torch.add(_323, torch.alias(ret401))
    _344 = torch.to(torch.alias(ret402), 6)
    ret403 = torch.pow(_344, 2)
    ret404 = torch.mean(torch.alias(ret403), [-1], True)
    ret405 = torch.add(torch.alias(ret404), CONSTANTS.c3)
    ret406 = torch.rsqrt(torch.alias(ret405))
    ret407 = torch.mul(_344, torch.alias(ret406))
    ret408 = torch.mul(CONSTANTS.c90, torch.alias(ret407))
    _345 = torch.alias(ret408)
    ret409 = torch.mul(_345, CONSTANTS.c91)
    ret410 = torch.quantize_per_tensor(torch.alias(ret409), 0.0080705936998128891, 160, 13)
    ret411 = torch.dequantize(torch.alias(ret410))
    ret412 = torch.linear(torch.alias(ret411), torch.dequantize(CONSTANTS.c92))
    input6 = torch.alias(ret412)
    ret413 = torch.silu(input6)
    _346 = torch.alias(ret413)
    ret414 = torch.mul(_345, CONSTANTS.c91)
    ret415 = torch.quantize_per_tensor(torch.alias(ret414), 0.0080705936998128891, 160, 13)
    ret416 = torch.dequantize(torch.alias(ret415))
    ret417 = torch.linear(torch.alias(ret416), torch.dequantize(CONSTANTS.c93))
    ret418 = torch.mul(_346, torch.alias(ret417))
    ret419 = torch.mul(torch.alias(ret418), CONSTANTS.c94)
    ret420 = torch.quantize_per_tensor(torch.alias(ret419), 0.014497091062366962, 76, 13)
    ret421 = torch.dequantize(torch.alias(ret420))
    ret422 = torch.linear(torch.alias(ret421), torch.dequantize(CONSTANTS.c95))
    ret423 = torch.add(_344, torch.alias(ret422))
    _347 = torch.to(torch.alias(ret423), 6)
    ret424 = torch.pow(_347, 2)
    ret425 = torch.mean(torch.alias(ret424), [-1], True)
    ret426 = torch.add(torch.alias(ret425), CONSTANTS.c3)
    ret427 = torch.rsqrt(torch.alias(ret426))
    ret428 = torch.mul(_347, torch.alias(ret427))
    ret429 = torch.mul(CONSTANTS.c96, torch.alias(ret428))
    _348 = torch.alias(ret429)
    ret430 = ops.prim.NumToTensor(torch.size(_348, 0))
    ret431 = ops.prim.NumToTensor(torch.size(_348, 1))
    _349 = int(torch.alias(ret430))
    _350 = int(torch.alias(ret431))
    ret432 = torch.mul(_348, CONSTANTS.c97)
    ret433 = torch.quantize_per_tensor(torch.alias(ret432), 0.014936136081814766, 132, 13)
    ret434 = torch.dequantize(torch.alias(ret433))
    ret435 = torch.linear(torch.alias(ret434), torch.dequantize(CONSTANTS.c98))
    _351 = torch.alias(ret435)
    _352 = [_349, _350, 32, 128]
    ret436 = torch.view(_351, _352)
    _353 = torch.alias(ret436)
    ret437 = torch.mul(_348, CONSTANTS.c97)
    ret438 = torch.quantize_per_tensor(torch.alias(ret437), 0.014936136081814766, 132, 13)
    ret439 = torch.dequantize(torch.alias(ret438))
    ret440 = torch.linear(torch.alias(ret439), torch.dequantize(CONSTANTS.c99))
    ret441 = torch.view(torch.alias(ret440), _352)
    _354 = torch.alias(ret441)
    ret442 = torch.mul(_348, CONSTANTS.c97)
    ret443 = torch.quantize_per_tensor(torch.alias(ret442), 0.014936136081814766, 132, 13)
    ret444 = torch.dequantize(torch.alias(ret443))
    ret445 = torch.linear(torch.alias(ret444), torch.dequantize(CONSTANTS.c100))
    ret446 = torch.view(torch.alias(ret445), _352)
    _355 = torch.alias(ret446)
    _356 = torch.contiguous(_332)
    _357 = torch.contiguous(_354)
    _358 = torch.contiguous(_353)
    ops.torch_ipex.rotary_position_embedding(_357, CONSTANTS.c9, _356, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_358, CONSTANTS.c9, _356, 32, 128, 64, 128)
    _359 = torch.contiguous(_62)
    _360 = torch.contiguous(_63)
    _361 = torch.contiguous(_64)
    _362 = torch.contiguous(_65)
    ret447 = torch.select(_362, 0, 0)
    ret448, ret449, ret450, ret451, ret452 = ops.torch_ipex.masked_multihead_self_attention(_358, _357, _355, _359, _360, _361, torch.alias(ret447), 11.313708498984761, 64, None, _178)
    _363 = torch.alias(ret448)
    _364 = torch.alias(ret450)
    _365 = torch.alias(ret451)
    _366 = torch.alias(ret452)
    ret453 = ops.prim.NumToTensor(torch.size(_358, 1))
    ret454 = torch.add(_362, torch.alias(ret453))
    _367 = torch.to(torch.alias(ret454), torch.device("cpu"), 4, False, True)
    ret455 = torch.transpose(_363, 1, 2)
    ret456 = torch.reshape(torch.alias(ret455), [_349, _350, 4096])
    ret457 = torch.mul(torch.alias(ret456), CONSTANTS.c101)
    ret458 = torch.quantize_per_tensor(torch.alias(ret457), 0.0066763521172106266, 130, 13)
    ret459 = torch.dequantize(torch.alias(ret458))
    ret460 = torch.linear(torch.alias(ret459), torch.dequantize(CONSTANTS.c102))
    ret461 = torch.add(_347, torch.alias(ret460))
    _368 = torch.to(torch.alias(ret461), 6)
    ret462 = torch.pow(_368, 2)
    ret463 = torch.mean(torch.alias(ret462), [-1], True)
    ret464 = torch.add(torch.alias(ret463), CONSTANTS.c3)
    ret465 = torch.rsqrt(torch.alias(ret464))
    ret466 = torch.mul(_368, torch.alias(ret465))
    ret467 = torch.mul(CONSTANTS.c103, torch.alias(ret466))
    _369 = torch.alias(ret467)
    ret468 = torch.mul(_369, CONSTANTS.c104)
    ret469 = torch.quantize_per_tensor(torch.alias(ret468), 0.0086581194773316383, 142, 13)
    ret470 = torch.dequantize(torch.alias(ret469))
    ret471 = torch.linear(torch.alias(ret470), torch.dequantize(CONSTANTS.c105))
    input7 = torch.alias(ret471)
    ret472 = torch.silu(input7)
    _370 = torch.alias(ret472)
    ret473 = torch.mul(_369, CONSTANTS.c104)
    ret474 = torch.quantize_per_tensor(torch.alias(ret473), 0.0086581194773316383, 142, 13)
    ret475 = torch.dequantize(torch.alias(ret474))
    ret476 = torch.linear(torch.alias(ret475), torch.dequantize(CONSTANTS.c106))
    ret477 = torch.mul(_370, torch.alias(ret476))
    ret478 = torch.mul(torch.alias(ret477), CONSTANTS.c107)
    ret479 = torch.quantize_per_tensor(torch.alias(ret478), 0.017848558723926544, 154, 13)
    ret480 = torch.dequantize(torch.alias(ret479))
    ret481 = torch.linear(torch.alias(ret480), torch.dequantize(CONSTANTS.c108))
    ret482 = torch.add(_368, torch.alias(ret481))
    _371 = torch.to(torch.alias(ret482), 6)
    ret483 = torch.pow(_371, 2)
    ret484 = torch.mean(torch.alias(ret483), [-1], True)
    ret485 = torch.add(torch.alias(ret484), CONSTANTS.c3)
    ret486 = torch.rsqrt(torch.alias(ret485))
    ret487 = torch.mul(_371, torch.alias(ret486))
    ret488 = torch.mul(CONSTANTS.c109, torch.alias(ret487))
    _372 = torch.alias(ret488)
    ret489 = ops.prim.NumToTensor(torch.size(_372, 0))
    ret490 = ops.prim.NumToTensor(torch.size(_372, 1))
    _373 = int(torch.alias(ret489))
    _374 = int(torch.alias(ret490))
    ret491 = torch.mul(_372, CONSTANTS.c110)
    ret492 = torch.quantize_per_tensor(torch.alias(ret491), 0.01481038611382246, 135, 13)
    ret493 = torch.dequantize(torch.alias(ret492))
    ret494 = torch.linear(torch.alias(ret493), torch.dequantize(CONSTANTS.c111))
    _375 = torch.alias(ret494)
    _376 = [_373, _374, 32, 128]
    ret495 = torch.view(_375, _376)
    _377 = torch.alias(ret495)
    ret496 = torch.mul(_372, CONSTANTS.c110)
    ret497 = torch.quantize_per_tensor(torch.alias(ret496), 0.01481038611382246, 135, 13)
    ret498 = torch.dequantize(torch.alias(ret497))
    ret499 = torch.linear(torch.alias(ret498), torch.dequantize(CONSTANTS.c112))
    ret500 = torch.view(torch.alias(ret499), _376)
    _378 = torch.alias(ret500)
    ret501 = torch.mul(_372, CONSTANTS.c110)
    ret502 = torch.quantize_per_tensor(torch.alias(ret501), 0.01481038611382246, 135, 13)
    ret503 = torch.dequantize(torch.alias(ret502))
    ret504 = torch.linear(torch.alias(ret503), torch.dequantize(CONSTANTS.c113))
    ret505 = torch.view(torch.alias(ret504), _376)
    _379 = torch.alias(ret505)
    _380 = torch.contiguous(_356)
    _381 = torch.contiguous(_378)
    _382 = torch.contiguous(_377)
    ops.torch_ipex.rotary_position_embedding(_381, CONSTANTS.c9, _380, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_382, CONSTANTS.c9, _380, 32, 128, 64, 128)
    _383 = torch.contiguous(_66)
    _384 = torch.contiguous(_67)
    _385 = torch.contiguous(_68)
    _386 = torch.contiguous(_69)
    ret506 = torch.select(_386, 0, 0)
    ret507, ret508, ret509, ret510, ret511 = ops.torch_ipex.masked_multihead_self_attention(_382, _381, _379, _383, _384, _385, torch.alias(ret506), 11.313708498984761, 64, None, _178)
    _387 = torch.alias(ret507)
    _388 = torch.alias(ret509)
    _389 = torch.alias(ret510)
    _390 = torch.alias(ret511)
    ret512 = ops.prim.NumToTensor(torch.size(_382, 1))
    ret513 = torch.add(_386, torch.alias(ret512))
    _391 = torch.to(torch.alias(ret513), torch.device("cpu"), 4, False, True)
    ret514 = torch.transpose(_387, 1, 2)
    ret515 = torch.reshape(torch.alias(ret514), [_373, _374, 4096])
    ret516 = torch.mul(torch.alias(ret515), CONSTANTS.c114)
    ret517 = torch.quantize_per_tensor(torch.alias(ret516), 0.0073519190773367882, 124, 13)
    ret518 = torch.dequantize(torch.alias(ret517))
    ret519 = torch.linear(torch.alias(ret518), torch.dequantize(CONSTANTS.c115))
    ret520 = torch.add(_371, torch.alias(ret519))
    _392 = torch.to(torch.alias(ret520), 6)
    ret521 = torch.pow(_392, 2)
    ret522 = torch.mean(torch.alias(ret521), [-1], True)
    ret523 = torch.add(torch.alias(ret522), CONSTANTS.c3)
    ret524 = torch.rsqrt(torch.alias(ret523))
    ret525 = torch.mul(_392, torch.alias(ret524))
    ret526 = torch.mul(CONSTANTS.c116, torch.alias(ret525))
    _393 = torch.alias(ret526)
    ret527 = torch.mul(_393, CONSTANTS.c117)
    ret528 = torch.quantize_per_tensor(torch.alias(ret527), 0.013476811349391937, 175, 13)
    ret529 = torch.dequantize(torch.alias(ret528))
    ret530 = torch.linear(torch.alias(ret529), torch.dequantize(CONSTANTS.c118))
    input8 = torch.alias(ret530)
    ret531 = torch.silu(input8)
    _394 = torch.alias(ret531)
    ret532 = torch.mul(_393, CONSTANTS.c117)
    ret533 = torch.quantize_per_tensor(torch.alias(ret532), 0.013476811349391937, 175, 13)
    ret534 = torch.dequantize(torch.alias(ret533))
    ret535 = torch.linear(torch.alias(ret534), torch.dequantize(CONSTANTS.c119))
    ret536 = torch.mul(_394, torch.alias(ret535))
    ret537 = torch.mul(torch.alias(ret536), CONSTANTS.c120)
    ret538 = torch.quantize_per_tensor(torch.alias(ret537), 0.021145178005099297, 72, 13)
    ret539 = torch.dequantize(torch.alias(ret538))
    ret540 = torch.linear(torch.alias(ret539), torch.dequantize(CONSTANTS.c121))
    ret541 = torch.add(_392, torch.alias(ret540))
    _395 = torch.to(torch.alias(ret541), 6)
    ret542 = torch.pow(_395, 2)
    ret543 = torch.mean(torch.alias(ret542), [-1], True)
    ret544 = torch.add(torch.alias(ret543), CONSTANTS.c3)
    ret545 = torch.rsqrt(torch.alias(ret544))
    ret546 = torch.mul(_395, torch.alias(ret545))
    ret547 = torch.mul(CONSTANTS.c122, torch.alias(ret546))
    _396 = torch.alias(ret547)
    ret548 = ops.prim.NumToTensor(torch.size(_396, 0))
    ret549 = ops.prim.NumToTensor(torch.size(_396, 1))
    _397 = int(torch.alias(ret548))
    _398 = int(torch.alias(ret549))
    ret550 = torch.mul(_396, CONSTANTS.c123)
    ret551 = torch.quantize_per_tensor(torch.alias(ret550), 0.017878454178571701, 137, 13)
    ret552 = torch.dequantize(torch.alias(ret551))
    ret553 = torch.linear(torch.alias(ret552), torch.dequantize(CONSTANTS.c124))
    _399 = torch.alias(ret553)
    _400 = [_397, _398, 32, 128]
    ret554 = torch.view(_399, _400)
    _401 = torch.alias(ret554)
    ret555 = torch.mul(_396, CONSTANTS.c123)
    ret556 = torch.quantize_per_tensor(torch.alias(ret555), 0.017878454178571701, 137, 13)
    ret557 = torch.dequantize(torch.alias(ret556))
    ret558 = torch.linear(torch.alias(ret557), torch.dequantize(CONSTANTS.c125))
    ret559 = torch.view(torch.alias(ret558), _400)
    _402 = torch.alias(ret559)
    ret560 = torch.mul(_396, CONSTANTS.c123)
    ret561 = torch.quantize_per_tensor(torch.alias(ret560), 0.017878454178571701, 137, 13)
    ret562 = torch.dequantize(torch.alias(ret561))
    ret563 = torch.linear(torch.alias(ret562), torch.dequantize(CONSTANTS.c126))
    ret564 = torch.view(torch.alias(ret563), _400)
    _403 = torch.alias(ret564)
    _404 = torch.contiguous(_380)
    _405 = torch.contiguous(_402)
    _406 = torch.contiguous(_401)
    ops.torch_ipex.rotary_position_embedding(_405, CONSTANTS.c9, _404, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_406, CONSTANTS.c9, _404, 32, 128, 64, 128)
    _407 = torch.contiguous(_70)
    _408 = torch.contiguous(_71)
    _409 = torch.contiguous(_72)
    _410 = torch.contiguous(_73)
    ret565 = torch.select(_410, 0, 0)
    ret566, ret567, ret568, ret569, ret570 = ops.torch_ipex.masked_multihead_self_attention(_406, _405, _403, _407, _408, _409, torch.alias(ret565), 11.313708498984761, 64, None, _178)
    _411 = torch.alias(ret566)
    _412 = torch.alias(ret568)
    _413 = torch.alias(ret569)
    _414 = torch.alias(ret570)
    ret571 = ops.prim.NumToTensor(torch.size(_406, 1))
    ret572 = torch.add(_410, torch.alias(ret571))
    _415 = torch.to(torch.alias(ret572), torch.device("cpu"), 4, False, True)
    ret573 = torch.transpose(_411, 1, 2)
    ret574 = torch.reshape(torch.alias(ret573), [_397, _398, 4096])
    ret575 = torch.mul(torch.alias(ret574), CONSTANTS.c127)
    ret576 = torch.quantize_per_tensor(torch.alias(ret575), 0.0058574192225933075, 128, 13)
    ret577 = torch.dequantize(torch.alias(ret576))
    ret578 = torch.linear(torch.alias(ret577), torch.dequantize(CONSTANTS.c128))
    ret579 = torch.add(_395, torch.alias(ret578))
    _416 = torch.to(torch.alias(ret579), 6)
    ret580 = torch.pow(_416, 2)
    ret581 = torch.mean(torch.alias(ret580), [-1], True)
    ret582 = torch.add(torch.alias(ret581), CONSTANTS.c3)
    ret583 = torch.rsqrt(torch.alias(ret582))
    ret584 = torch.mul(_416, torch.alias(ret583))
    ret585 = torch.mul(CONSTANTS.c129, torch.alias(ret584))
    _417 = torch.alias(ret585)
    ret586 = torch.mul(_417, CONSTANTS.c130)
    ret587 = torch.quantize_per_tensor(torch.alias(ret586), 0.014187857508659363, 185, 13)
    ret588 = torch.dequantize(torch.alias(ret587))
    ret589 = torch.linear(torch.alias(ret588), torch.dequantize(CONSTANTS.c131))
    input9 = torch.alias(ret589)
    ret590 = torch.silu(input9)
    _418 = torch.alias(ret590)
    ret591 = torch.mul(_417, CONSTANTS.c130)
    ret592 = torch.quantize_per_tensor(torch.alias(ret591), 0.014187857508659363, 185, 13)
    ret593 = torch.dequantize(torch.alias(ret592))
    ret594 = torch.linear(torch.alias(ret593), torch.dequantize(CONSTANTS.c132))
    ret595 = torch.mul(_418, torch.alias(ret594))
    ret596 = torch.mul(torch.alias(ret595), CONSTANTS.c133)
    ret597 = torch.quantize_per_tensor(torch.alias(ret596), 0.018012054264545441, 158, 13)
    ret598 = torch.dequantize(torch.alias(ret597))
    ret599 = torch.linear(torch.alias(ret598), torch.dequantize(CONSTANTS.c134))
    ret600 = torch.add(_416, torch.alias(ret599))
    _419 = torch.to(torch.alias(ret600), 6)
    ret601 = torch.pow(_419, 2)
    ret602 = torch.mean(torch.alias(ret601), [-1], True)
    ret603 = torch.add(torch.alias(ret602), CONSTANTS.c3)
    ret604 = torch.rsqrt(torch.alias(ret603))
    ret605 = torch.mul(_419, torch.alias(ret604))
    ret606 = torch.mul(CONSTANTS.c135, torch.alias(ret605))
    _420 = torch.alias(ret606)
    ret607 = ops.prim.NumToTensor(torch.size(_420, 0))
    ret608 = ops.prim.NumToTensor(torch.size(_420, 1))
    _421 = int(torch.alias(ret607))
    _422 = int(torch.alias(ret608))
    ret609 = torch.mul(_420, CONSTANTS.c136)
    ret610 = torch.quantize_per_tensor(torch.alias(ret609), 0.018671400845050812, 157, 13)
    ret611 = torch.dequantize(torch.alias(ret610))
    ret612 = torch.linear(torch.alias(ret611), torch.dequantize(CONSTANTS.c137))
    _423 = torch.alias(ret612)
    _424 = [_421, _422, 32, 128]
    ret613 = torch.view(_423, _424)
    _425 = torch.alias(ret613)
    ret614 = torch.mul(_420, CONSTANTS.c136)
    ret615 = torch.quantize_per_tensor(torch.alias(ret614), 0.018671400845050812, 157, 13)
    ret616 = torch.dequantize(torch.alias(ret615))
    ret617 = torch.linear(torch.alias(ret616), torch.dequantize(CONSTANTS.c138))
    ret618 = torch.view(torch.alias(ret617), _424)
    _426 = torch.alias(ret618)
    ret619 = torch.mul(_420, CONSTANTS.c136)
    ret620 = torch.quantize_per_tensor(torch.alias(ret619), 0.018671400845050812, 157, 13)
    ret621 = torch.dequantize(torch.alias(ret620))
    ret622 = torch.linear(torch.alias(ret621), torch.dequantize(CONSTANTS.c139))
    ret623 = torch.view(torch.alias(ret622), _424)
    _427 = torch.alias(ret623)
    _428 = torch.contiguous(_404)
    _429 = torch.contiguous(_426)
    _430 = torch.contiguous(_425)
    ops.torch_ipex.rotary_position_embedding(_429, CONSTANTS.c9, _428, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_430, CONSTANTS.c9, _428, 32, 128, 64, 128)
    _431 = torch.contiguous(_74)
    _432 = torch.contiguous(_75)
    _433 = torch.contiguous(_76)
    _434 = torch.contiguous(_77)
    ret624 = torch.select(_434, 0, 0)
    ret625, ret626, ret627, ret628, ret629 = ops.torch_ipex.masked_multihead_self_attention(_430, _429, _427, _431, _432, _433, torch.alias(ret624), 11.313708498984761, 64, None, _178)
    _435 = torch.alias(ret625)
    _436 = torch.alias(ret627)
    _437 = torch.alias(ret628)
    _438 = torch.alias(ret629)
    ret630 = ops.prim.NumToTensor(torch.size(_430, 1))
    ret631 = torch.add(_434, torch.alias(ret630))
    _439 = torch.to(torch.alias(ret631), torch.device("cpu"), 4, False, True)
    ret632 = torch.transpose(_435, 1, 2)
    ret633 = torch.reshape(torch.alias(ret632), [_421, _422, 4096])
    ret634 = torch.mul(torch.alias(ret633), CONSTANTS.c140)
    ret635 = torch.quantize_per_tensor(torch.alias(ret634), 0.0049250088632106781, 123, 13)
    ret636 = torch.dequantize(torch.alias(ret635))
    ret637 = torch.linear(torch.alias(ret636), torch.dequantize(CONSTANTS.c141))
    ret638 = torch.add(_419, torch.alias(ret637))
    _440 = torch.to(torch.alias(ret638), 6)
    ret639 = torch.pow(_440, 2)
    ret640 = torch.mean(torch.alias(ret639), [-1], True)
    ret641 = torch.add(torch.alias(ret640), CONSTANTS.c3)
    ret642 = torch.rsqrt(torch.alias(ret641))
    ret643 = torch.mul(_440, torch.alias(ret642))
    ret644 = torch.mul(CONSTANTS.c142, torch.alias(ret643))
    _441 = torch.alias(ret644)
    ret645 = torch.mul(_441, CONSTANTS.c143)
    ret646 = torch.quantize_per_tensor(torch.alias(ret645), 0.0088300788775086403, 144, 13)
    ret647 = torch.dequantize(torch.alias(ret646))
    ret648 = torch.linear(torch.alias(ret647), torch.dequantize(CONSTANTS.c144))
    input10 = torch.alias(ret648)
    ret649 = torch.silu(input10)
    _442 = torch.alias(ret649)
    ret650 = torch.mul(_441, CONSTANTS.c143)
    ret651 = torch.quantize_per_tensor(torch.alias(ret650), 0.0088300788775086403, 144, 13)
    ret652 = torch.dequantize(torch.alias(ret651))
    ret653 = torch.linear(torch.alias(ret652), torch.dequantize(CONSTANTS.c145))
    ret654 = torch.mul(_442, torch.alias(ret653))
    ret655 = torch.mul(torch.alias(ret654), CONSTANTS.c146)
    ret656 = torch.quantize_per_tensor(torch.alias(ret655), 0.0087425326928496361, 128, 13)
    ret657 = torch.dequantize(torch.alias(ret656))
    ret658 = torch.linear(torch.alias(ret657), torch.dequantize(CONSTANTS.c147))
    ret659 = torch.add(_440, torch.alias(ret658))
    _443 = torch.to(torch.alias(ret659), 6)
    ret660 = torch.pow(_443, 2)
    ret661 = torch.mean(torch.alias(ret660), [-1], True)
    ret662 = torch.add(torch.alias(ret661), CONSTANTS.c3)
    ret663 = torch.rsqrt(torch.alias(ret662))
    ret664 = torch.mul(_443, torch.alias(ret663))
    ret665 = torch.mul(CONSTANTS.c148, torch.alias(ret664))
    _444 = torch.alias(ret665)
    ret666 = ops.prim.NumToTensor(torch.size(_444, 0))
    ret667 = ops.prim.NumToTensor(torch.size(_444, 1))
    _445 = int(torch.alias(ret666))
    _446 = int(torch.alias(ret667))
    ret668 = torch.mul(_444, CONSTANTS.c149)
    ret669 = torch.quantize_per_tensor(torch.alias(ret668), 0.019093651324510574, 148, 13)
    ret670 = torch.dequantize(torch.alias(ret669))
    ret671 = torch.linear(torch.alias(ret670), torch.dequantize(CONSTANTS.c150))
    _447 = torch.alias(ret671)
    _448 = [_445, _446, 32, 128]
    ret672 = torch.view(_447, _448)
    _449 = torch.alias(ret672)
    ret673 = torch.mul(_444, CONSTANTS.c149)
    ret674 = torch.quantize_per_tensor(torch.alias(ret673), 0.019093651324510574, 148, 13)
    ret675 = torch.dequantize(torch.alias(ret674))
    ret676 = torch.linear(torch.alias(ret675), torch.dequantize(CONSTANTS.c151))
    ret677 = torch.view(torch.alias(ret676), _448)
    _450 = torch.alias(ret677)
    ret678 = torch.mul(_444, CONSTANTS.c149)
    ret679 = torch.quantize_per_tensor(torch.alias(ret678), 0.019093651324510574, 148, 13)
    ret680 = torch.dequantize(torch.alias(ret679))
    ret681 = torch.linear(torch.alias(ret680), torch.dequantize(CONSTANTS.c152))
    ret682 = torch.view(torch.alias(ret681), _448)
    _451 = torch.alias(ret682)
    _452 = torch.contiguous(_428)
    _453 = torch.contiguous(_450)
    _454 = torch.contiguous(_449)
    ops.torch_ipex.rotary_position_embedding(_453, CONSTANTS.c9, _452, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_454, CONSTANTS.c9, _452, 32, 128, 64, 128)
    _455 = torch.contiguous(_78)
    _456 = torch.contiguous(_79)
    _457 = torch.contiguous(_80)
    _458 = torch.contiguous(_81)
    ret683 = torch.select(_458, 0, 0)
    ret684, ret685, ret686, ret687, ret688 = ops.torch_ipex.masked_multihead_self_attention(_454, _453, _451, _455, _456, _457, torch.alias(ret683), 11.313708498984761, 64, None, _178)
    _459 = torch.alias(ret684)
    _460 = torch.alias(ret686)
    _461 = torch.alias(ret687)
    _462 = torch.alias(ret688)
    ret689 = ops.prim.NumToTensor(torch.size(_454, 1))
    ret690 = torch.add(_458, torch.alias(ret689))
    _463 = torch.to(torch.alias(ret690), torch.device("cpu"), 4, False, True)
    ret691 = torch.transpose(_459, 1, 2)
    ret692 = torch.reshape(torch.alias(ret691), [_445, _446, 4096])
    ret693 = torch.mul(torch.alias(ret692), CONSTANTS.c153)
    ret694 = torch.quantize_per_tensor(torch.alias(ret693), 0.005466013215482235, 120, 13)
    ret695 = torch.dequantize(torch.alias(ret694))
    ret696 = torch.linear(torch.alias(ret695), torch.dequantize(CONSTANTS.c154))
    ret697 = torch.add(_443, torch.alias(ret696))
    _464 = torch.to(torch.alias(ret697), 6)
    ret698 = torch.pow(_464, 2)
    ret699 = torch.mean(torch.alias(ret698), [-1], True)
    ret700 = torch.add(torch.alias(ret699), CONSTANTS.c3)
    ret701 = torch.rsqrt(torch.alias(ret700))
    ret702 = torch.mul(_464, torch.alias(ret701))
    ret703 = torch.mul(CONSTANTS.c155, torch.alias(ret702))
    _465 = torch.alias(ret703)
    ret704 = torch.mul(_465, CONSTANTS.c156)
    ret705 = torch.quantize_per_tensor(torch.alias(ret704), 0.0098971910774707794, 153, 13)
    ret706 = torch.dequantize(torch.alias(ret705))
    ret707 = torch.linear(torch.alias(ret706), torch.dequantize(CONSTANTS.c157))
    input11 = torch.alias(ret707)
    ret708 = torch.silu(input11)
    _466 = torch.alias(ret708)
    ret709 = torch.mul(_465, CONSTANTS.c156)
    ret710 = torch.quantize_per_tensor(torch.alias(ret709), 0.0098971910774707794, 153, 13)
    ret711 = torch.dequantize(torch.alias(ret710))
    ret712 = torch.linear(torch.alias(ret711), torch.dequantize(CONSTANTS.c158))
    ret713 = torch.mul(_466, torch.alias(ret712))
    ret714 = torch.mul(torch.alias(ret713), CONSTANTS.c159)
    ret715 = torch.quantize_per_tensor(torch.alias(ret714), 0.0075590210035443306, 111, 13)
    ret716 = torch.dequantize(torch.alias(ret715))
    ret717 = torch.linear(torch.alias(ret716), torch.dequantize(CONSTANTS.c160))
    ret718 = torch.add(_464, torch.alias(ret717))
    _467 = torch.to(torch.alias(ret718), 6)
    ret719 = torch.pow(_467, 2)
    ret720 = torch.mean(torch.alias(ret719), [-1], True)
    ret721 = torch.add(torch.alias(ret720), CONSTANTS.c3)
    ret722 = torch.rsqrt(torch.alias(ret721))
    ret723 = torch.mul(_467, torch.alias(ret722))
    ret724 = torch.mul(CONSTANTS.c161, torch.alias(ret723))
    _468 = torch.alias(ret724)
    ret725 = ops.prim.NumToTensor(torch.size(_468, 0))
    ret726 = ops.prim.NumToTensor(torch.size(_468, 1))
    _469 = int(torch.alias(ret725))
    _470 = int(torch.alias(ret726))
    ret727 = torch.mul(_468, CONSTANTS.c162)
    ret728 = torch.quantize_per_tensor(torch.alias(ret727), 0.018070893362164497, 146, 13)
    ret729 = torch.dequantize(torch.alias(ret728))
    ret730 = torch.linear(torch.alias(ret729), torch.dequantize(CONSTANTS.c163))
    _471 = torch.alias(ret730)
    _472 = [_469, _470, 32, 128]
    ret731 = torch.view(_471, _472)
    _473 = torch.alias(ret731)
    ret732 = torch.mul(_468, CONSTANTS.c162)
    ret733 = torch.quantize_per_tensor(torch.alias(ret732), 0.018070893362164497, 146, 13)
    ret734 = torch.dequantize(torch.alias(ret733))
    ret735 = torch.linear(torch.alias(ret734), torch.dequantize(CONSTANTS.c164))
    ret736 = torch.view(torch.alias(ret735), _472)
    _474 = torch.alias(ret736)
    ret737 = torch.mul(_468, CONSTANTS.c162)
    ret738 = torch.quantize_per_tensor(torch.alias(ret737), 0.018070893362164497, 146, 13)
    ret739 = torch.dequantize(torch.alias(ret738))
    ret740 = torch.linear(torch.alias(ret739), torch.dequantize(CONSTANTS.c165))
    ret741 = torch.view(torch.alias(ret740), _472)
    _475 = torch.alias(ret741)
    _476 = torch.contiguous(_452)
    _477 = torch.contiguous(_474)
    _478 = torch.contiguous(_473)
    ops.torch_ipex.rotary_position_embedding(_477, CONSTANTS.c9, _476, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_478, CONSTANTS.c9, _476, 32, 128, 64, 128)
    _479 = torch.contiguous(_82)
    _480 = torch.contiguous(_83)
    _481 = torch.contiguous(_84)
    _482 = torch.contiguous(_85)
    ret742 = torch.select(_482, 0, 0)
    ret743, ret744, ret745, ret746, ret747 = ops.torch_ipex.masked_multihead_self_attention(_478, _477, _475, _479, _480, _481, torch.alias(ret742), 11.313708498984761, 64, None, _178)
    _483 = torch.alias(ret743)
    _484 = torch.alias(ret745)
    _485 = torch.alias(ret746)
    _486 = torch.alias(ret747)
    ret748 = ops.prim.NumToTensor(torch.size(_478, 1))
    ret749 = torch.add(_482, torch.alias(ret748))
    _487 = torch.to(torch.alias(ret749), torch.device("cpu"), 4, False, True)
    ret750 = torch.transpose(_483, 1, 2)
    ret751 = torch.reshape(torch.alias(ret750), [_469, _470, 4096])
    ret752 = torch.mul(torch.alias(ret751), CONSTANTS.c166)
    ret753 = torch.quantize_per_tensor(torch.alias(ret752), 0.0058236201293766499, 149, 13)
    ret754 = torch.dequantize(torch.alias(ret753))
    ret755 = torch.linear(torch.alias(ret754), torch.dequantize(CONSTANTS.c167))
    ret756 = torch.add(_467, torch.alias(ret755))
    _488 = torch.to(torch.alias(ret756), 6)
    ret757 = torch.pow(_488, 2)
    ret758 = torch.mean(torch.alias(ret757), [-1], True)
    ret759 = torch.add(torch.alias(ret758), CONSTANTS.c3)
    ret760 = torch.rsqrt(torch.alias(ret759))
    ret761 = torch.mul(_488, torch.alias(ret760))
    ret762 = torch.mul(CONSTANTS.c168, torch.alias(ret761))
    _489 = torch.alias(ret762)
    ret763 = torch.mul(_489, CONSTANTS.c169)
    ret764 = torch.quantize_per_tensor(torch.alias(ret763), 0.0088409967720508575, 125, 13)
    ret765 = torch.dequantize(torch.alias(ret764))
    ret766 = torch.linear(torch.alias(ret765), torch.dequantize(CONSTANTS.c170))
    input12 = torch.alias(ret766)
    ret767 = torch.silu(input12)
    _490 = torch.alias(ret767)
    ret768 = torch.mul(_489, CONSTANTS.c169)
    ret769 = torch.quantize_per_tensor(torch.alias(ret768), 0.0088409967720508575, 125, 13)
    ret770 = torch.dequantize(torch.alias(ret769))
    ret771 = torch.linear(torch.alias(ret770), torch.dequantize(CONSTANTS.c171))
    ret772 = torch.mul(_490, torch.alias(ret771))
    ret773 = torch.mul(torch.alias(ret772), CONSTANTS.c172)
    ret774 = torch.quantize_per_tensor(torch.alias(ret773), 0.0067416154779493809, 119, 13)
    ret775 = torch.dequantize(torch.alias(ret774))
    ret776 = torch.linear(torch.alias(ret775), torch.dequantize(CONSTANTS.c173))
    ret777 = torch.add(_488, torch.alias(ret776))
    _491 = torch.to(torch.alias(ret777), 6)
    ret778 = torch.pow(_491, 2)
    ret779 = torch.mean(torch.alias(ret778), [-1], True)
    ret780 = torch.add(torch.alias(ret779), CONSTANTS.c3)
    ret781 = torch.rsqrt(torch.alias(ret780))
    ret782 = torch.mul(_491, torch.alias(ret781))
    ret783 = torch.mul(CONSTANTS.c174, torch.alias(ret782))
    _492 = torch.alias(ret783)
    ret784 = ops.prim.NumToTensor(torch.size(_492, 0))
    ret785 = ops.prim.NumToTensor(torch.size(_492, 1))
    _493 = int(torch.alias(ret784))
    _494 = int(torch.alias(ret785))
    ret786 = torch.mul(_492, CONSTANTS.c175)
    ret787 = torch.quantize_per_tensor(torch.alias(ret786), 0.017163204029202461, 134, 13)
    ret788 = torch.dequantize(torch.alias(ret787))
    ret789 = torch.linear(torch.alias(ret788), torch.dequantize(CONSTANTS.c176))
    _495 = torch.alias(ret789)
    _496 = [_493, _494, 32, 128]
    ret790 = torch.view(_495, _496)
    _497 = torch.alias(ret790)
    ret791 = torch.mul(_492, CONSTANTS.c175)
    ret792 = torch.quantize_per_tensor(torch.alias(ret791), 0.017163204029202461, 134, 13)
    ret793 = torch.dequantize(torch.alias(ret792))
    ret794 = torch.linear(torch.alias(ret793), torch.dequantize(CONSTANTS.c177))
    ret795 = torch.view(torch.alias(ret794), _496)
    _498 = torch.alias(ret795)
    ret796 = torch.mul(_492, CONSTANTS.c175)
    ret797 = torch.quantize_per_tensor(torch.alias(ret796), 0.017163204029202461, 134, 13)
    ret798 = torch.dequantize(torch.alias(ret797))
    ret799 = torch.linear(torch.alias(ret798), torch.dequantize(CONSTANTS.c178))
    ret800 = torch.view(torch.alias(ret799), _496)
    _499 = torch.alias(ret800)
    _500 = torch.contiguous(_476)
    _501 = torch.contiguous(_498)
    _502 = torch.contiguous(_497)
    ops.torch_ipex.rotary_position_embedding(_501, CONSTANTS.c9, _500, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_502, CONSTANTS.c9, _500, 32, 128, 64, 128)
    _503 = torch.contiguous(_86)
    _504 = torch.contiguous(_87)
    _505 = torch.contiguous(_88)
    _506 = torch.contiguous(_89)
    ret801 = torch.select(_506, 0, 0)
    ret802, ret803, ret804, ret805, ret806 = ops.torch_ipex.masked_multihead_self_attention(_502, _501, _499, _503, _504, _505, torch.alias(ret801), 11.313708498984761, 64, None, _178)
    _507 = torch.alias(ret802)
    _508 = torch.alias(ret804)
    _509 = torch.alias(ret805)
    _510 = torch.alias(ret806)
    ret807 = ops.prim.NumToTensor(torch.size(_502, 1))
    ret808 = torch.add(_506, torch.alias(ret807))
    _511 = torch.to(torch.alias(ret808), torch.device("cpu"), 4, False, True)
    ret809 = torch.transpose(_507, 1, 2)
    ret810 = torch.reshape(torch.alias(ret809), [_493, _494, 4096])
    ret811 = torch.mul(torch.alias(ret810), CONSTANTS.c179)
    ret812 = torch.quantize_per_tensor(torch.alias(ret811), 0.0056223119609057903, 133, 13)
    ret813 = torch.dequantize(torch.alias(ret812))
    ret814 = torch.linear(torch.alias(ret813), torch.dequantize(CONSTANTS.c180))
    ret815 = torch.add(_491, torch.alias(ret814))
    _512 = torch.to(torch.alias(ret815), 6)
    ret816 = torch.pow(_512, 2)
    ret817 = torch.mean(torch.alias(ret816), [-1], True)
    ret818 = torch.add(torch.alias(ret817), CONSTANTS.c3)
    ret819 = torch.rsqrt(torch.alias(ret818))
    ret820 = torch.mul(_512, torch.alias(ret819))
    ret821 = torch.mul(CONSTANTS.c181, torch.alias(ret820))
    _513 = torch.alias(ret821)
    ret822 = torch.mul(_513, CONSTANTS.c182)
    ret823 = torch.quantize_per_tensor(torch.alias(ret822), 0.011115584522485733, 157, 13)
    ret824 = torch.dequantize(torch.alias(ret823))
    ret825 = torch.linear(torch.alias(ret824), torch.dequantize(CONSTANTS.c183))
    input13 = torch.alias(ret825)
    ret826 = torch.silu(input13)
    _514 = torch.alias(ret826)
    ret827 = torch.mul(_513, CONSTANTS.c182)
    ret828 = torch.quantize_per_tensor(torch.alias(ret827), 0.011115584522485733, 157, 13)
    ret829 = torch.dequantize(torch.alias(ret828))
    ret830 = torch.linear(torch.alias(ret829), torch.dequantize(CONSTANTS.c184))
    ret831 = torch.mul(_514, torch.alias(ret830))
    ret832 = torch.mul(torch.alias(ret831), CONSTANTS.c185)
    ret833 = torch.quantize_per_tensor(torch.alias(ret832), 0.0099622281268239021, 118, 13)
    ret834 = torch.dequantize(torch.alias(ret833))
    ret835 = torch.linear(torch.alias(ret834), torch.dequantize(CONSTANTS.c186))
    ret836 = torch.add(_512, torch.alias(ret835))
    _515 = torch.to(torch.alias(ret836), 6)
    ret837 = torch.pow(_515, 2)
    ret838 = torch.mean(torch.alias(ret837), [-1], True)
    ret839 = torch.add(torch.alias(ret838), CONSTANTS.c3)
    ret840 = torch.rsqrt(torch.alias(ret839))
    ret841 = torch.mul(_515, torch.alias(ret840))
    ret842 = torch.mul(CONSTANTS.c187, torch.alias(ret841))
    _516 = torch.alias(ret842)
    ret843 = ops.prim.NumToTensor(torch.size(_516, 0))
    ret844 = ops.prim.NumToTensor(torch.size(_516, 1))
    _517 = int(torch.alias(ret843))
    _518 = int(torch.alias(ret844))
    ret845 = torch.mul(_516, CONSTANTS.c188)
    ret846 = torch.quantize_per_tensor(torch.alias(ret845), 0.018831918016076088, 150, 13)
    ret847 = torch.dequantize(torch.alias(ret846))
    ret848 = torch.linear(torch.alias(ret847), torch.dequantize(CONSTANTS.c189))
    _519 = torch.alias(ret848)
    _520 = [_517, _518, 32, 128]
    ret849 = torch.view(_519, _520)
    _521 = torch.alias(ret849)
    ret850 = torch.mul(_516, CONSTANTS.c188)
    ret851 = torch.quantize_per_tensor(torch.alias(ret850), 0.018831918016076088, 150, 13)
    ret852 = torch.dequantize(torch.alias(ret851))
    ret853 = torch.linear(torch.alias(ret852), torch.dequantize(CONSTANTS.c190))
    ret854 = torch.view(torch.alias(ret853), _520)
    _522 = torch.alias(ret854)
    ret855 = torch.mul(_516, CONSTANTS.c188)
    ret856 = torch.quantize_per_tensor(torch.alias(ret855), 0.018831918016076088, 150, 13)
    ret857 = torch.dequantize(torch.alias(ret856))
    ret858 = torch.linear(torch.alias(ret857), torch.dequantize(CONSTANTS.c191))
    ret859 = torch.view(torch.alias(ret858), _520)
    _523 = torch.alias(ret859)
    _524 = torch.contiguous(_500)
    _525 = torch.contiguous(_522)
    _526 = torch.contiguous(_521)
    ops.torch_ipex.rotary_position_embedding(_525, CONSTANTS.c9, _524, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_526, CONSTANTS.c9, _524, 32, 128, 64, 128)
    _527 = torch.contiguous(_90)
    _528 = torch.contiguous(_91)
    _529 = torch.contiguous(_92)
    _530 = torch.contiguous(_93)
    ret860 = torch.select(_530, 0, 0)
    ret861, ret862, ret863, ret864, ret865 = ops.torch_ipex.masked_multihead_self_attention(_526, _525, _523, _527, _528, _529, torch.alias(ret860), 11.313708498984761, 64, None, _178)
    _531 = torch.alias(ret861)
    _532 = torch.alias(ret863)
    _533 = torch.alias(ret864)
    _534 = torch.alias(ret865)
    ret866 = ops.prim.NumToTensor(torch.size(_526, 1))
    ret867 = torch.add(_530, torch.alias(ret866))
    _535 = torch.to(torch.alias(ret867), torch.device("cpu"), 4, False, True)
    ret868 = torch.transpose(_531, 1, 2)
    ret869 = torch.reshape(torch.alias(ret868), [_517, _518, 4096])
    ret870 = torch.mul(torch.alias(ret869), CONSTANTS.c192)
    ret871 = torch.quantize_per_tensor(torch.alias(ret870), 0.0054230391979217529, 139, 13)
    ret872 = torch.dequantize(torch.alias(ret871))
    ret873 = torch.linear(torch.alias(ret872), torch.dequantize(CONSTANTS.c193))
    ret874 = torch.add(_515, torch.alias(ret873))
    _536 = torch.to(torch.alias(ret874), 6)
    ret875 = torch.pow(_536, 2)
    ret876 = torch.mean(torch.alias(ret875), [-1], True)
    ret877 = torch.add(torch.alias(ret876), CONSTANTS.c3)
    ret878 = torch.rsqrt(torch.alias(ret877))
    ret879 = torch.mul(_536, torch.alias(ret878))
    ret880 = torch.mul(CONSTANTS.c194, torch.alias(ret879))
    _537 = torch.alias(ret880)
    ret881 = torch.mul(_537, CONSTANTS.c195)
    ret882 = torch.quantize_per_tensor(torch.alias(ret881), 0.0085279243066906929, 141, 13)
    ret883 = torch.dequantize(torch.alias(ret882))
    ret884 = torch.linear(torch.alias(ret883), torch.dequantize(CONSTANTS.c196))
    input14 = torch.alias(ret884)
    ret885 = torch.silu(input14)
    _538 = torch.alias(ret885)
    ret886 = torch.mul(_537, CONSTANTS.c195)
    ret887 = torch.quantize_per_tensor(torch.alias(ret886), 0.0085279243066906929, 141, 13)
    ret888 = torch.dequantize(torch.alias(ret887))
    ret889 = torch.linear(torch.alias(ret888), torch.dequantize(CONSTANTS.c197))
    ret890 = torch.mul(_538, torch.alias(ret889))
    ret891 = torch.mul(torch.alias(ret890), CONSTANTS.c198)
    ret892 = torch.quantize_per_tensor(torch.alias(ret891), 0.0074095763266086578, 111, 13)
    ret893 = torch.dequantize(torch.alias(ret892))
    ret894 = torch.linear(torch.alias(ret893), torch.dequantize(CONSTANTS.c199))
    ret895 = torch.add(_536, torch.alias(ret894))
    _539 = torch.to(torch.alias(ret895), 6)
    ret896 = torch.pow(_539, 2)
    ret897 = torch.mean(torch.alias(ret896), [-1], True)
    ret898 = torch.add(torch.alias(ret897), CONSTANTS.c3)
    ret899 = torch.rsqrt(torch.alias(ret898))
    ret900 = torch.mul(_539, torch.alias(ret899))
    ret901 = torch.mul(CONSTANTS.c200, torch.alias(ret900))
    _540 = torch.alias(ret901)
    ret902 = ops.prim.NumToTensor(torch.size(_540, 0))
    ret903 = ops.prim.NumToTensor(torch.size(_540, 1))
    _541 = int(torch.alias(ret902))
    _542 = int(torch.alias(ret903))
    ret904 = torch.mul(_540, CONSTANTS.c201)
    ret905 = torch.quantize_per_tensor(torch.alias(ret904), 0.016403626650571823, 137, 13)
    ret906 = torch.dequantize(torch.alias(ret905))
    ret907 = torch.linear(torch.alias(ret906), torch.dequantize(CONSTANTS.c202))
    _543 = torch.alias(ret907)
    _544 = [_541, _542, 32, 128]
    ret908 = torch.view(_543, _544)
    _545 = torch.alias(ret908)
    ret909 = torch.mul(_540, CONSTANTS.c201)
    ret910 = torch.quantize_per_tensor(torch.alias(ret909), 0.016403626650571823, 137, 13)
    ret911 = torch.dequantize(torch.alias(ret910))
    ret912 = torch.linear(torch.alias(ret911), torch.dequantize(CONSTANTS.c203))
    ret913 = torch.view(torch.alias(ret912), _544)
    _546 = torch.alias(ret913)
    ret914 = torch.mul(_540, CONSTANTS.c201)
    ret915 = torch.quantize_per_tensor(torch.alias(ret914), 0.016403626650571823, 137, 13)
    ret916 = torch.dequantize(torch.alias(ret915))
    ret917 = torch.linear(torch.alias(ret916), torch.dequantize(CONSTANTS.c204))
    ret918 = torch.view(torch.alias(ret917), _544)
    _547 = torch.alias(ret918)
    _548 = torch.contiguous(_524)
    _549 = torch.contiguous(_546)
    _550 = torch.contiguous(_545)
    ops.torch_ipex.rotary_position_embedding(_549, CONSTANTS.c9, _548, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_550, CONSTANTS.c9, _548, 32, 128, 64, 128)
    _551 = torch.contiguous(_94)
    _552 = torch.contiguous(_95)
    _553 = torch.contiguous(_96)
    _554 = torch.contiguous(_97)
    ret919 = torch.select(_554, 0, 0)
    ret920, ret921, ret922, ret923, ret924 = ops.torch_ipex.masked_multihead_self_attention(_550, _549, _547, _551, _552, _553, torch.alias(ret919), 11.313708498984761, 64, None, _178)
    _555 = torch.alias(ret920)
    _556 = torch.alias(ret922)
    _557 = torch.alias(ret923)
    _558 = torch.alias(ret924)
    ret925 = ops.prim.NumToTensor(torch.size(_550, 1))
    ret926 = torch.add(_554, torch.alias(ret925))
    _559 = torch.to(torch.alias(ret926), torch.device("cpu"), 4, False, True)
    ret927 = torch.transpose(_555, 1, 2)
    ret928 = torch.reshape(torch.alias(ret927), [_541, _542, 4096])
    ret929 = torch.mul(torch.alias(ret928), CONSTANTS.c205)
    ret930 = torch.quantize_per_tensor(torch.alias(ret929), 0.0051660304889082909, 135, 13)
    ret931 = torch.dequantize(torch.alias(ret930))
    ret932 = torch.linear(torch.alias(ret931), torch.dequantize(CONSTANTS.c206))
    ret933 = torch.add(_539, torch.alias(ret932))
    _560 = torch.to(torch.alias(ret933), 6)
    ret934 = torch.pow(_560, 2)
    ret935 = torch.mean(torch.alias(ret934), [-1], True)
    ret936 = torch.add(torch.alias(ret935), CONSTANTS.c3)
    ret937 = torch.rsqrt(torch.alias(ret936))
    ret938 = torch.mul(_560, torch.alias(ret937))
    ret939 = torch.mul(CONSTANTS.c207, torch.alias(ret938))
    _561 = torch.alias(ret939)
    ret940 = torch.mul(_561, CONSTANTS.c208)
    ret941 = torch.quantize_per_tensor(torch.alias(ret940), 0.0099168550223112106, 138, 13)
    ret942 = torch.dequantize(torch.alias(ret941))
    ret943 = torch.linear(torch.alias(ret942), torch.dequantize(CONSTANTS.c209))
    input15 = torch.alias(ret943)
    ret944 = torch.silu(input15)
    _562 = torch.alias(ret944)
    ret945 = torch.mul(_561, CONSTANTS.c208)
    ret946 = torch.quantize_per_tensor(torch.alias(ret945), 0.0099168550223112106, 138, 13)
    ret947 = torch.dequantize(torch.alias(ret946))
    ret948 = torch.linear(torch.alias(ret947), torch.dequantize(CONSTANTS.c210))
    ret949 = torch.mul(_562, torch.alias(ret948))
    ret950 = torch.mul(torch.alias(ret949), CONSTANTS.c211)
    ret951 = torch.quantize_per_tensor(torch.alias(ret950), 0.01247837021946907, 150, 13)
    ret952 = torch.dequantize(torch.alias(ret951))
    ret953 = torch.linear(torch.alias(ret952), torch.dequantize(CONSTANTS.c212))
    ret954 = torch.add(_560, torch.alias(ret953))
    _563 = torch.to(torch.alias(ret954), 6)
    ret955 = torch.pow(_563, 2)
    ret956 = torch.mean(torch.alias(ret955), [-1], True)
    ret957 = torch.add(torch.alias(ret956), CONSTANTS.c3)
    ret958 = torch.rsqrt(torch.alias(ret957))
    ret959 = torch.mul(_563, torch.alias(ret958))
    ret960 = torch.mul(CONSTANTS.c213, torch.alias(ret959))
    _564 = torch.alias(ret960)
    ret961 = ops.prim.NumToTensor(torch.size(_564, 0))
    ret962 = ops.prim.NumToTensor(torch.size(_564, 1))
    _565 = int(torch.alias(ret961))
    _566 = int(torch.alias(ret962))
    ret963 = torch.mul(_564, CONSTANTS.c214)
    ret964 = torch.quantize_per_tensor(torch.alias(ret963), 0.017723772674798965, 129, 13)
    ret965 = torch.dequantize(torch.alias(ret964))
    ret966 = torch.linear(torch.alias(ret965), torch.dequantize(CONSTANTS.c215))
    _567 = torch.alias(ret966)
    _568 = [_565, _566, 32, 128]
    ret967 = torch.view(_567, _568)
    _569 = torch.alias(ret967)
    ret968 = torch.mul(_564, CONSTANTS.c214)
    ret969 = torch.quantize_per_tensor(torch.alias(ret968), 0.017723772674798965, 129, 13)
    ret970 = torch.dequantize(torch.alias(ret969))
    ret971 = torch.linear(torch.alias(ret970), torch.dequantize(CONSTANTS.c216))
    ret972 = torch.view(torch.alias(ret971), _568)
    _570 = torch.alias(ret972)
    ret973 = torch.mul(_564, CONSTANTS.c214)
    ret974 = torch.quantize_per_tensor(torch.alias(ret973), 0.017723772674798965, 129, 13)
    ret975 = torch.dequantize(torch.alias(ret974))
    ret976 = torch.linear(torch.alias(ret975), torch.dequantize(CONSTANTS.c217))
    ret977 = torch.view(torch.alias(ret976), _568)
    _571 = torch.alias(ret977)
    _572 = torch.contiguous(_548)
    _573 = torch.contiguous(_570)
    _574 = torch.contiguous(_569)
    ops.torch_ipex.rotary_position_embedding(_573, CONSTANTS.c9, _572, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_574, CONSTANTS.c9, _572, 32, 128, 64, 128)
    _575 = torch.contiguous(_98)
    _576 = torch.contiguous(_99)
    _577 = torch.contiguous(_100)
    _578 = torch.contiguous(_101)
    ret978 = torch.select(_578, 0, 0)
    ret979, ret980, ret981, ret982, ret983 = ops.torch_ipex.masked_multihead_self_attention(_574, _573, _571, _575, _576, _577, torch.alias(ret978), 11.313708498984761, 64, None, _178)
    _579 = torch.alias(ret979)
    _580 = torch.alias(ret981)
    _581 = torch.alias(ret982)
    _582 = torch.alias(ret983)
    ret984 = ops.prim.NumToTensor(torch.size(_574, 1))
    ret985 = torch.add(_578, torch.alias(ret984))
    _583 = torch.to(torch.alias(ret985), torch.device("cpu"), 4, False, True)
    ret986 = torch.transpose(_579, 1, 2)
    ret987 = torch.reshape(torch.alias(ret986), [_565, _566, 4096])
    ret988 = torch.mul(torch.alias(ret987), CONSTANTS.c218)
    ret989 = torch.quantize_per_tensor(torch.alias(ret988), 0.0055800960399210453, 143, 13)
    ret990 = torch.dequantize(torch.alias(ret989))
    ret991 = torch.linear(torch.alias(ret990), torch.dequantize(CONSTANTS.c219))
    ret992 = torch.add(_563, torch.alias(ret991))
    _584 = torch.to(torch.alias(ret992), 6)
    ret993 = torch.pow(_584, 2)
    ret994 = torch.mean(torch.alias(ret993), [-1], True)
    ret995 = torch.add(torch.alias(ret994), CONSTANTS.c3)
    ret996 = torch.rsqrt(torch.alias(ret995))
    ret997 = torch.mul(_584, torch.alias(ret996))
    ret998 = torch.mul(CONSTANTS.c220, torch.alias(ret997))
    _585 = torch.alias(ret998)
    ret999 = torch.mul(_585, CONSTANTS.c221)
    ret1000 = torch.quantize_per_tensor(torch.alias(ret999), 0.011000807397067547, 117, 13)
    ret1001 = torch.dequantize(torch.alias(ret1000))
    ret1002 = torch.linear(torch.alias(ret1001), torch.dequantize(CONSTANTS.c222))
    input16 = torch.alias(ret1002)
    ret1003 = torch.silu(input16)
    _586 = torch.alias(ret1003)
    ret1004 = torch.mul(_585, CONSTANTS.c221)
    ret1005 = torch.quantize_per_tensor(torch.alias(ret1004), 0.011000807397067547, 117, 13)
    ret1006 = torch.dequantize(torch.alias(ret1005))
    ret1007 = torch.linear(torch.alias(ret1006), torch.dequantize(CONSTANTS.c223))
    ret1008 = torch.mul(_586, torch.alias(ret1007))
    ret1009 = torch.mul(torch.alias(ret1008), CONSTANTS.c224)
    ret1010 = torch.quantize_per_tensor(torch.alias(ret1009), 0.014644350856542587, 98, 13)
    ret1011 = torch.dequantize(torch.alias(ret1010))
    ret1012 = torch.linear(torch.alias(ret1011), torch.dequantize(CONSTANTS.c225))
    ret1013 = torch.add(_584, torch.alias(ret1012))
    _587 = torch.to(torch.alias(ret1013), 6)
    ret1014 = torch.pow(_587, 2)
    ret1015 = torch.mean(torch.alias(ret1014), [-1], True)
    ret1016 = torch.add(torch.alias(ret1015), CONSTANTS.c3)
    ret1017 = torch.rsqrt(torch.alias(ret1016))
    ret1018 = torch.mul(_587, torch.alias(ret1017))
    ret1019 = torch.mul(CONSTANTS.c226, torch.alias(ret1018))
    _588 = torch.alias(ret1019)
    ret1020 = ops.prim.NumToTensor(torch.size(_588, 0))
    ret1021 = ops.prim.NumToTensor(torch.size(_588, 1))
    _589 = int(torch.alias(ret1020))
    _590 = int(torch.alias(ret1021))
    ret1022 = torch.mul(_588, CONSTANTS.c227)
    ret1023 = torch.quantize_per_tensor(torch.alias(ret1022), 0.017349220812320709, 113, 13)
    ret1024 = torch.dequantize(torch.alias(ret1023))
    ret1025 = torch.linear(torch.alias(ret1024), torch.dequantize(CONSTANTS.c228))
    _591 = torch.alias(ret1025)
    _592 = [_589, _590, 32, 128]
    ret1026 = torch.view(_591, _592)
    _593 = torch.alias(ret1026)
    ret1027 = torch.mul(_588, CONSTANTS.c227)
    ret1028 = torch.quantize_per_tensor(torch.alias(ret1027), 0.017349220812320709, 113, 13)
    ret1029 = torch.dequantize(torch.alias(ret1028))
    ret1030 = torch.linear(torch.alias(ret1029), torch.dequantize(CONSTANTS.c229))
    ret1031 = torch.view(torch.alias(ret1030), _592)
    _594 = torch.alias(ret1031)
    ret1032 = torch.mul(_588, CONSTANTS.c227)
    ret1033 = torch.quantize_per_tensor(torch.alias(ret1032), 0.017349220812320709, 113, 13)
    ret1034 = torch.dequantize(torch.alias(ret1033))
    ret1035 = torch.linear(torch.alias(ret1034), torch.dequantize(CONSTANTS.c230))
    ret1036 = torch.view(torch.alias(ret1035), _592)
    _595 = torch.alias(ret1036)
    _596 = torch.contiguous(_572)
    _597 = torch.contiguous(_594)
    _598 = torch.contiguous(_593)
    ops.torch_ipex.rotary_position_embedding(_597, CONSTANTS.c9, _596, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_598, CONSTANTS.c9, _596, 32, 128, 64, 128)
    _599 = torch.contiguous(_102)
    _600 = torch.contiguous(_103)
    _601 = torch.contiguous(_104)
    _602 = torch.contiguous(_105)
    ret1037 = torch.select(_602, 0, 0)
    ret1038, ret1039, ret1040, ret1041, ret1042 = ops.torch_ipex.masked_multihead_self_attention(_598, _597, _595, _599, _600, _601, torch.alias(ret1037), 11.313708498984761, 64, None, _178)
    _603 = torch.alias(ret1038)
    _604 = torch.alias(ret1040)
    _605 = torch.alias(ret1041)
    _606 = torch.alias(ret1042)
    ret1043 = ops.prim.NumToTensor(torch.size(_598, 1))
    ret1044 = torch.add(_602, torch.alias(ret1043))
    _607 = torch.to(torch.alias(ret1044), torch.device("cpu"), 4, False, True)
    ret1045 = torch.transpose(_603, 1, 2)
    ret1046 = torch.reshape(torch.alias(ret1045), [_589, _590, 4096])
    ret1047 = torch.mul(torch.alias(ret1046), CONSTANTS.c231)
    ret1048 = torch.quantize_per_tensor(torch.alias(ret1047), 0.0065912338905036449, 125, 13)
    ret1049 = torch.dequantize(torch.alias(ret1048))
    ret1050 = torch.linear(torch.alias(ret1049), torch.dequantize(CONSTANTS.c232))
    ret1051 = torch.add(_587, torch.alias(ret1050))
    _608 = torch.to(torch.alias(ret1051), 6)
    ret1052 = torch.pow(_608, 2)
    ret1053 = torch.mean(torch.alias(ret1052), [-1], True)
    ret1054 = torch.add(torch.alias(ret1053), CONSTANTS.c3)
    ret1055 = torch.rsqrt(torch.alias(ret1054))
    ret1056 = torch.mul(_608, torch.alias(ret1055))
    ret1057 = torch.mul(CONSTANTS.c233, torch.alias(ret1056))
    _609 = torch.alias(ret1057)
    ret1058 = torch.mul(_609, CONSTANTS.c234)
    ret1059 = torch.quantize_per_tensor(torch.alias(ret1058), 0.0094560757279396057, 153, 13)
    ret1060 = torch.dequantize(torch.alias(ret1059))
    ret1061 = torch.linear(torch.alias(ret1060), torch.dequantize(CONSTANTS.c235))
    input17 = torch.alias(ret1061)
    ret1062 = torch.silu(input17)
    _610 = torch.alias(ret1062)
    ret1063 = torch.mul(_609, CONSTANTS.c234)
    ret1064 = torch.quantize_per_tensor(torch.alias(ret1063), 0.0094560757279396057, 153, 13)
    ret1065 = torch.dequantize(torch.alias(ret1064))
    ret1066 = torch.linear(torch.alias(ret1065), torch.dequantize(CONSTANTS.c236))
    ret1067 = torch.mul(_610, torch.alias(ret1066))
    ret1068 = torch.mul(torch.alias(ret1067), CONSTANTS.c237)
    ret1069 = torch.quantize_per_tensor(torch.alias(ret1068), 0.012257411144673824, 154, 13)
    ret1070 = torch.dequantize(torch.alias(ret1069))
    ret1071 = torch.linear(torch.alias(ret1070), torch.dequantize(CONSTANTS.c238))
    ret1072 = torch.add(_608, torch.alias(ret1071))
    _611 = torch.to(torch.alias(ret1072), 6)
    ret1073 = torch.pow(_611, 2)
    ret1074 = torch.mean(torch.alias(ret1073), [-1], True)
    ret1075 = torch.add(torch.alias(ret1074), CONSTANTS.c3)
    ret1076 = torch.rsqrt(torch.alias(ret1075))
    ret1077 = torch.mul(_611, torch.alias(ret1076))
    ret1078 = torch.mul(CONSTANTS.c239, torch.alias(ret1077))
    _612 = torch.alias(ret1078)
    ret1079 = ops.prim.NumToTensor(torch.size(_612, 0))
    ret1080 = ops.prim.NumToTensor(torch.size(_612, 1))
    _613 = int(torch.alias(ret1079))
    _614 = int(torch.alias(ret1080))
    ret1081 = torch.mul(_612, CONSTANTS.c240)
    ret1082 = torch.quantize_per_tensor(torch.alias(ret1081), 0.016766596585512161, 124, 13)
    ret1083 = torch.dequantize(torch.alias(ret1082))
    ret1084 = torch.linear(torch.alias(ret1083), torch.dequantize(CONSTANTS.c241))
    _615 = torch.alias(ret1084)
    _616 = [_613, _614, 32, 128]
    ret1085 = torch.view(_615, _616)
    _617 = torch.alias(ret1085)
    ret1086 = torch.mul(_612, CONSTANTS.c240)
    ret1087 = torch.quantize_per_tensor(torch.alias(ret1086), 0.016766596585512161, 124, 13)
    ret1088 = torch.dequantize(torch.alias(ret1087))
    ret1089 = torch.linear(torch.alias(ret1088), torch.dequantize(CONSTANTS.c242))
    ret1090 = torch.view(torch.alias(ret1089), _616)
    _618 = torch.alias(ret1090)
    ret1091 = torch.mul(_612, CONSTANTS.c240)
    ret1092 = torch.quantize_per_tensor(torch.alias(ret1091), 0.016766596585512161, 124, 13)
    ret1093 = torch.dequantize(torch.alias(ret1092))
    ret1094 = torch.linear(torch.alias(ret1093), torch.dequantize(CONSTANTS.c243))
    ret1095 = torch.view(torch.alias(ret1094), _616)
    _619 = torch.alias(ret1095)
    _620 = torch.contiguous(_596)
    _621 = torch.contiguous(_618)
    _622 = torch.contiguous(_617)
    ops.torch_ipex.rotary_position_embedding(_621, CONSTANTS.c9, _620, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_622, CONSTANTS.c9, _620, 32, 128, 64, 128)
    _623 = torch.contiguous(_106)
    _624 = torch.contiguous(_107)
    _625 = torch.contiguous(_108)
    _626 = torch.contiguous(_109)
    ret1096 = torch.select(_626, 0, 0)
    ret1097, ret1098, ret1099, ret1100, ret1101 = ops.torch_ipex.masked_multihead_self_attention(_622, _621, _619, _623, _624, _625, torch.alias(ret1096), 11.313708498984761, 64, None, _178)
    _627 = torch.alias(ret1097)
    _628 = torch.alias(ret1099)
    _629 = torch.alias(ret1100)
    _630 = torch.alias(ret1101)
    ret1102 = ops.prim.NumToTensor(torch.size(_622, 1))
    ret1103 = torch.add(_626, torch.alias(ret1102))
    _631 = torch.to(torch.alias(ret1103), torch.device("cpu"), 4, False, True)
    ret1104 = torch.transpose(_627, 1, 2)
    ret1105 = torch.reshape(torch.alias(ret1104), [_613, _614, 4096])
    ret1106 = torch.mul(torch.alias(ret1105), CONSTANTS.c244)
    ret1107 = torch.quantize_per_tensor(torch.alias(ret1106), 0.0058918832801282406, 128, 13)
    ret1108 = torch.dequantize(torch.alias(ret1107))
    ret1109 = torch.linear(torch.alias(ret1108), torch.dequantize(CONSTANTS.c245))
    ret1110 = torch.add(_611, torch.alias(ret1109))
    _632 = torch.to(torch.alias(ret1110), 6)
    ret1111 = torch.pow(_632, 2)
    ret1112 = torch.mean(torch.alias(ret1111), [-1], True)
    ret1113 = torch.add(torch.alias(ret1112), CONSTANTS.c3)
    ret1114 = torch.rsqrt(torch.alias(ret1113))
    ret1115 = torch.mul(_632, torch.alias(ret1114))
    ret1116 = torch.mul(CONSTANTS.c246, torch.alias(ret1115))
    _633 = torch.alias(ret1116)
    ret1117 = torch.mul(_633, CONSTANTS.c247)
    ret1118 = torch.quantize_per_tensor(torch.alias(ret1117), 0.0087625123560428619, 144, 13)
    ret1119 = torch.dequantize(torch.alias(ret1118))
    ret1120 = torch.linear(torch.alias(ret1119), torch.dequantize(CONSTANTS.c248))
    input18 = torch.alias(ret1120)
    ret1121 = torch.silu(input18)
    _634 = torch.alias(ret1121)
    ret1122 = torch.mul(_633, CONSTANTS.c247)
    ret1123 = torch.quantize_per_tensor(torch.alias(ret1122), 0.0087625123560428619, 144, 13)
    ret1124 = torch.dequantize(torch.alias(ret1123))
    ret1125 = torch.linear(torch.alias(ret1124), torch.dequantize(CONSTANTS.c249))
    ret1126 = torch.mul(_634, torch.alias(ret1125))
    ret1127 = torch.mul(torch.alias(ret1126), CONSTANTS.c250)
    ret1128 = torch.quantize_per_tensor(torch.alias(ret1127), 0.017730604857206345, 165, 13)
    ret1129 = torch.dequantize(torch.alias(ret1128))
    ret1130 = torch.linear(torch.alias(ret1129), torch.dequantize(CONSTANTS.c251))
    ret1131 = torch.add(_632, torch.alias(ret1130))
    _635 = torch.to(torch.alias(ret1131), 6)
    ret1132 = torch.pow(_635, 2)
    ret1133 = torch.mean(torch.alias(ret1132), [-1], True)
    ret1134 = torch.add(torch.alias(ret1133), CONSTANTS.c3)
    ret1135 = torch.rsqrt(torch.alias(ret1134))
    ret1136 = torch.mul(_635, torch.alias(ret1135))
    ret1137 = torch.mul(CONSTANTS.c252, torch.alias(ret1136))
    _636 = torch.alias(ret1137)
    ret1138 = ops.prim.NumToTensor(torch.size(_636, 0))
    ret1139 = ops.prim.NumToTensor(torch.size(_636, 1))
    _637 = int(torch.alias(ret1138))
    _638 = int(torch.alias(ret1139))
    ret1140 = torch.mul(_636, CONSTANTS.c253)
    ret1141 = torch.quantize_per_tensor(torch.alias(ret1140), 0.015395338647067547, 121, 13)
    ret1142 = torch.dequantize(torch.alias(ret1141))
    ret1143 = torch.linear(torch.alias(ret1142), torch.dequantize(CONSTANTS.c254))
    _639 = torch.alias(ret1143)
    _640 = [_637, _638, 32, 128]
    ret1144 = torch.view(_639, _640)
    _641 = torch.alias(ret1144)
    ret1145 = torch.mul(_636, CONSTANTS.c253)
    ret1146 = torch.quantize_per_tensor(torch.alias(ret1145), 0.015395338647067547, 121, 13)
    ret1147 = torch.dequantize(torch.alias(ret1146))
    ret1148 = torch.linear(torch.alias(ret1147), torch.dequantize(CONSTANTS.c255))
    ret1149 = torch.view(torch.alias(ret1148), _640)
    _642 = torch.alias(ret1149)
    ret1150 = torch.mul(_636, CONSTANTS.c253)
    ret1151 = torch.quantize_per_tensor(torch.alias(ret1150), 0.015395338647067547, 121, 13)
    ret1152 = torch.dequantize(torch.alias(ret1151))
    ret1153 = torch.linear(torch.alias(ret1152), torch.dequantize(CONSTANTS.c256))
    ret1154 = torch.view(torch.alias(ret1153), _640)
    _643 = torch.alias(ret1154)
    _644 = torch.contiguous(_620)
    _645 = torch.contiguous(_642)
    _646 = torch.contiguous(_641)
    ops.torch_ipex.rotary_position_embedding(_645, CONSTANTS.c9, _644, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_646, CONSTANTS.c9, _644, 32, 128, 64, 128)
    _647 = torch.contiguous(_110)
    _648 = torch.contiguous(_111)
    _649 = torch.contiguous(_112)
    _650 = torch.contiguous(_113)
    ret1155 = torch.select(_650, 0, 0)
    ret1156, ret1157, ret1158, ret1159, ret1160 = ops.torch_ipex.masked_multihead_self_attention(_646, _645, _643, _647, _648, _649, torch.alias(ret1155), 11.313708498984761, 64, None, _178)
    _651 = torch.alias(ret1156)
    _652 = torch.alias(ret1158)
    _653 = torch.alias(ret1159)
    _654 = torch.alias(ret1160)
    ret1161 = ops.prim.NumToTensor(torch.size(_646, 1))
    ret1162 = torch.add(_650, torch.alias(ret1161))
    _655 = torch.to(torch.alias(ret1162), torch.device("cpu"), 4, False, True)
    ret1163 = torch.transpose(_651, 1, 2)
    ret1164 = torch.reshape(torch.alias(ret1163), [_637, _638, 4096])
    ret1165 = torch.mul(torch.alias(ret1164), CONSTANTS.c257)
    ret1166 = torch.quantize_per_tensor(torch.alias(ret1165), 0.0071108201518654823, 128, 13)
    ret1167 = torch.dequantize(torch.alias(ret1166))
    ret1168 = torch.linear(torch.alias(ret1167), torch.dequantize(CONSTANTS.c258))
    ret1169 = torch.add(_635, torch.alias(ret1168))
    _656 = torch.to(torch.alias(ret1169), 6)
    ret1170 = torch.pow(_656, 2)
    ret1171 = torch.mean(torch.alias(ret1170), [-1], True)
    ret1172 = torch.add(torch.alias(ret1171), CONSTANTS.c3)
    ret1173 = torch.rsqrt(torch.alias(ret1172))
    ret1174 = torch.mul(_656, torch.alias(ret1173))
    ret1175 = torch.mul(CONSTANTS.c259, torch.alias(ret1174))
    _657 = torch.alias(ret1175)
    ret1176 = torch.mul(_657, CONSTANTS.c260)
    ret1177 = torch.quantize_per_tensor(torch.alias(ret1176), 0.010891192592680454, 125, 13)
    ret1178 = torch.dequantize(torch.alias(ret1177))
    ret1179 = torch.linear(torch.alias(ret1178), torch.dequantize(CONSTANTS.c261))
    input19 = torch.alias(ret1179)
    ret1180 = torch.silu(input19)
    _658 = torch.alias(ret1180)
    ret1181 = torch.mul(_657, CONSTANTS.c260)
    ret1182 = torch.quantize_per_tensor(torch.alias(ret1181), 0.010891192592680454, 125, 13)
    ret1183 = torch.dequantize(torch.alias(ret1182))
    ret1184 = torch.linear(torch.alias(ret1183), torch.dequantize(CONSTANTS.c262))
    ret1185 = torch.mul(_658, torch.alias(ret1184))
    ret1186 = torch.mul(torch.alias(ret1185), CONSTANTS.c263)
    ret1187 = torch.quantize_per_tensor(torch.alias(ret1186), 0.016595160588622093, 127, 13)
    ret1188 = torch.dequantize(torch.alias(ret1187))
    ret1189 = torch.linear(torch.alias(ret1188), torch.dequantize(CONSTANTS.c264))
    ret1190 = torch.add(_656, torch.alias(ret1189))
    _659 = torch.to(torch.alias(ret1190), 6)
    ret1191 = torch.pow(_659, 2)
    ret1192 = torch.mean(torch.alias(ret1191), [-1], True)
    ret1193 = torch.add(torch.alias(ret1192), CONSTANTS.c3)
    ret1194 = torch.rsqrt(torch.alias(ret1193))
    ret1195 = torch.mul(_659, torch.alias(ret1194))
    ret1196 = torch.mul(CONSTANTS.c265, torch.alias(ret1195))
    _660 = torch.alias(ret1196)
    ret1197 = ops.prim.NumToTensor(torch.size(_660, 0))
    ret1198 = ops.prim.NumToTensor(torch.size(_660, 1))
    _661 = int(torch.alias(ret1197))
    _662 = int(torch.alias(ret1198))
    ret1199 = torch.mul(_660, CONSTANTS.c266)
    ret1200 = torch.quantize_per_tensor(torch.alias(ret1199), 0.017955750226974487, 110, 13)
    ret1201 = torch.dequantize(torch.alias(ret1200))
    ret1202 = torch.linear(torch.alias(ret1201), torch.dequantize(CONSTANTS.c267))
    _663 = torch.alias(ret1202)
    _664 = [_661, _662, 32, 128]
    ret1203 = torch.view(_663, _664)
    _665 = torch.alias(ret1203)
    ret1204 = torch.mul(_660, CONSTANTS.c266)
    ret1205 = torch.quantize_per_tensor(torch.alias(ret1204), 0.017955750226974487, 110, 13)
    ret1206 = torch.dequantize(torch.alias(ret1205))
    ret1207 = torch.linear(torch.alias(ret1206), torch.dequantize(CONSTANTS.c268))
    ret1208 = torch.view(torch.alias(ret1207), _664)
    _666 = torch.alias(ret1208)
    ret1209 = torch.mul(_660, CONSTANTS.c266)
    ret1210 = torch.quantize_per_tensor(torch.alias(ret1209), 0.017955750226974487, 110, 13)
    ret1211 = torch.dequantize(torch.alias(ret1210))
    ret1212 = torch.linear(torch.alias(ret1211), torch.dequantize(CONSTANTS.c269))
    ret1213 = torch.view(torch.alias(ret1212), _664)
    _667 = torch.alias(ret1213)
    _668 = torch.contiguous(_644)
    _669 = torch.contiguous(_666)
    _670 = torch.contiguous(_665)
    ops.torch_ipex.rotary_position_embedding(_669, CONSTANTS.c9, _668, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_670, CONSTANTS.c9, _668, 32, 128, 64, 128)
    _671 = torch.contiguous(_114)
    _672 = torch.contiguous(_115)
    _673 = torch.contiguous(_116)
    _674 = torch.contiguous(_117)
    ret1214 = torch.select(_674, 0, 0)
    ret1215, ret1216, ret1217, ret1218, ret1219 = ops.torch_ipex.masked_multihead_self_attention(_670, _669, _667, _671, _672, _673, torch.alias(ret1214), 11.313708498984761, 64, None, _178)
    _675 = torch.alias(ret1215)
    _676 = torch.alias(ret1217)
    _677 = torch.alias(ret1218)
    _678 = torch.alias(ret1219)
    ret1220 = ops.prim.NumToTensor(torch.size(_670, 1))
    ret1221 = torch.add(_674, torch.alias(ret1220))
    _679 = torch.to(torch.alias(ret1221), torch.device("cpu"), 4, False, True)
    ret1222 = torch.transpose(_675, 1, 2)
    ret1223 = torch.reshape(torch.alias(ret1222), [_661, _662, 4096])
    ret1224 = torch.mul(torch.alias(ret1223), CONSTANTS.c270)
    ret1225 = torch.quantize_per_tensor(torch.alias(ret1224), 0.0070724710822105408, 127, 13)
    ret1226 = torch.dequantize(torch.alias(ret1225))
    ret1227 = torch.linear(torch.alias(ret1226), torch.dequantize(CONSTANTS.c271))
    ret1228 = torch.add(_659, torch.alias(ret1227))
    _680 = torch.to(torch.alias(ret1228), 6)
    ret1229 = torch.pow(_680, 2)
    ret1230 = torch.mean(torch.alias(ret1229), [-1], True)
    ret1231 = torch.add(torch.alias(ret1230), CONSTANTS.c3)
    ret1232 = torch.rsqrt(torch.alias(ret1231))
    ret1233 = torch.mul(_680, torch.alias(ret1232))
    ret1234 = torch.mul(CONSTANTS.c272, torch.alias(ret1233))
    _681 = torch.alias(ret1234)
    ret1235 = torch.mul(_681, CONSTANTS.c273)
    ret1236 = torch.quantize_per_tensor(torch.alias(ret1235), 0.0080923698842525482, 154, 13)
    ret1237 = torch.dequantize(torch.alias(ret1236))
    ret1238 = torch.linear(torch.alias(ret1237), torch.dequantize(CONSTANTS.c274))
    input20 = torch.alias(ret1238)
    ret1239 = torch.silu(input20)
    _682 = torch.alias(ret1239)
    ret1240 = torch.mul(_681, CONSTANTS.c273)
    ret1241 = torch.quantize_per_tensor(torch.alias(ret1240), 0.0080923698842525482, 154, 13)
    ret1242 = torch.dequantize(torch.alias(ret1241))
    ret1243 = torch.linear(torch.alias(ret1242), torch.dequantize(CONSTANTS.c275))
    ret1244 = torch.mul(_682, torch.alias(ret1243))
    ret1245 = torch.mul(torch.alias(ret1244), CONSTANTS.c276)
    ret1246 = torch.quantize_per_tensor(torch.alias(ret1245), 0.012765162624418736, 98, 13)
    ret1247 = torch.dequantize(torch.alias(ret1246))
    ret1248 = torch.linear(torch.alias(ret1247), torch.dequantize(CONSTANTS.c277))
    ret1249 = torch.add(_680, torch.alias(ret1248))
    _683 = torch.to(torch.alias(ret1249), 6)
    ret1250 = torch.pow(_683, 2)
    ret1251 = torch.mean(torch.alias(ret1250), [-1], True)
    ret1252 = torch.add(torch.alias(ret1251), CONSTANTS.c3)
    ret1253 = torch.rsqrt(torch.alias(ret1252))
    ret1254 = torch.mul(_683, torch.alias(ret1253))
    ret1255 = torch.mul(CONSTANTS.c278, torch.alias(ret1254))
    _684 = torch.alias(ret1255)
    ret1256 = ops.prim.NumToTensor(torch.size(_684, 0))
    ret1257 = ops.prim.NumToTensor(torch.size(_684, 1))
    _685 = int(torch.alias(ret1256))
    _686 = int(torch.alias(ret1257))
    ret1258 = torch.mul(_684, CONSTANTS.c279)
    ret1259 = torch.quantize_per_tensor(torch.alias(ret1258), 0.018253374844789505, 128, 13)
    ret1260 = torch.dequantize(torch.alias(ret1259))
    ret1261 = torch.linear(torch.alias(ret1260), torch.dequantize(CONSTANTS.c280))
    _687 = torch.alias(ret1261)
    _688 = [_685, _686, 32, 128]
    ret1262 = torch.view(_687, _688)
    _689 = torch.alias(ret1262)
    ret1263 = torch.mul(_684, CONSTANTS.c279)
    ret1264 = torch.quantize_per_tensor(torch.alias(ret1263), 0.018253374844789505, 128, 13)
    ret1265 = torch.dequantize(torch.alias(ret1264))
    ret1266 = torch.linear(torch.alias(ret1265), torch.dequantize(CONSTANTS.c281))
    ret1267 = torch.view(torch.alias(ret1266), _688)
    _690 = torch.alias(ret1267)
    ret1268 = torch.mul(_684, CONSTANTS.c279)
    ret1269 = torch.quantize_per_tensor(torch.alias(ret1268), 0.018253374844789505, 128, 13)
    ret1270 = torch.dequantize(torch.alias(ret1269))
    ret1271 = torch.linear(torch.alias(ret1270), torch.dequantize(CONSTANTS.c282))
    ret1272 = torch.view(torch.alias(ret1271), _688)
    _691 = torch.alias(ret1272)
    _692 = torch.contiguous(_668)
    _693 = torch.contiguous(_690)
    _694 = torch.contiguous(_689)
    ops.torch_ipex.rotary_position_embedding(_693, CONSTANTS.c9, _692, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_694, CONSTANTS.c9, _692, 32, 128, 64, 128)
    _695 = torch.contiguous(_118)
    _696 = torch.contiguous(_119)
    _697 = torch.contiguous(_120)
    _698 = torch.contiguous(_121)
    ret1273 = torch.select(_698, 0, 0)
    ret1274, ret1275, ret1276, ret1277, ret1278 = ops.torch_ipex.masked_multihead_self_attention(_694, _693, _691, _695, _696, _697, torch.alias(ret1273), 11.313708498984761, 64, None, _178)
    _699 = torch.alias(ret1274)
    _700 = torch.alias(ret1276)
    _701 = torch.alias(ret1277)
    _702 = torch.alias(ret1278)
    ret1279 = ops.prim.NumToTensor(torch.size(_694, 1))
    ret1280 = torch.add(_698, torch.alias(ret1279))
    _703 = torch.to(torch.alias(ret1280), torch.device("cpu"), 4, False, True)
    ret1281 = torch.transpose(_699, 1, 2)
    ret1282 = torch.reshape(torch.alias(ret1281), [_685, _686, 4096])
    ret1283 = torch.mul(torch.alias(ret1282), CONSTANTS.c283)
    ret1284 = torch.quantize_per_tensor(torch.alias(ret1283), 0.0074194790795445442, 128, 13)
    ret1285 = torch.dequantize(torch.alias(ret1284))
    ret1286 = torch.linear(torch.alias(ret1285), torch.dequantize(CONSTANTS.c284))
    ret1287 = torch.add(_683, torch.alias(ret1286))
    _704 = torch.to(torch.alias(ret1287), 6)
    ret1288 = torch.pow(_704, 2)
    ret1289 = torch.mean(torch.alias(ret1288), [-1], True)
    ret1290 = torch.add(torch.alias(ret1289), CONSTANTS.c3)
    ret1291 = torch.rsqrt(torch.alias(ret1290))
    ret1292 = torch.mul(_704, torch.alias(ret1291))
    ret1293 = torch.mul(CONSTANTS.c285, torch.alias(ret1292))
    _705 = torch.alias(ret1293)
    ret1294 = torch.mul(_705, CONSTANTS.c286)
    ret1295 = torch.quantize_per_tensor(torch.alias(ret1294), 0.0084121143445372581, 158, 13)
    ret1296 = torch.dequantize(torch.alias(ret1295))
    ret1297 = torch.linear(torch.alias(ret1296), torch.dequantize(CONSTANTS.c287))
    input21 = torch.alias(ret1297)
    ret1298 = torch.silu(input21)
    _706 = torch.alias(ret1298)
    ret1299 = torch.mul(_705, CONSTANTS.c286)
    ret1300 = torch.quantize_per_tensor(torch.alias(ret1299), 0.0084121143445372581, 158, 13)
    ret1301 = torch.dequantize(torch.alias(ret1300))
    ret1302 = torch.linear(torch.alias(ret1301), torch.dequantize(CONSTANTS.c288))
    ret1303 = torch.mul(_706, torch.alias(ret1302))
    ret1304 = torch.mul(torch.alias(ret1303), CONSTANTS.c289)
    ret1305 = torch.quantize_per_tensor(torch.alias(ret1304), 0.0093297641724348068, 120, 13)
    ret1306 = torch.dequantize(torch.alias(ret1305))
    ret1307 = torch.linear(torch.alias(ret1306), torch.dequantize(CONSTANTS.c290))
    ret1308 = torch.add(_704, torch.alias(ret1307))
    _707 = torch.to(torch.alias(ret1308), 6)
    ret1309 = torch.pow(_707, 2)
    ret1310 = torch.mean(torch.alias(ret1309), [-1], True)
    ret1311 = torch.add(torch.alias(ret1310), CONSTANTS.c3)
    ret1312 = torch.rsqrt(torch.alias(ret1311))
    ret1313 = torch.mul(_707, torch.alias(ret1312))
    ret1314 = torch.mul(CONSTANTS.c291, torch.alias(ret1313))
    _708 = torch.alias(ret1314)
    ret1315 = ops.prim.NumToTensor(torch.size(_708, 0))
    ret1316 = ops.prim.NumToTensor(torch.size(_708, 1))
    _709 = int(torch.alias(ret1315))
    _710 = int(torch.alias(ret1316))
    ret1317 = torch.mul(_708, CONSTANTS.c292)
    ret1318 = torch.quantize_per_tensor(torch.alias(ret1317), 0.016428142786026001, 116, 13)
    ret1319 = torch.dequantize(torch.alias(ret1318))
    ret1320 = torch.linear(torch.alias(ret1319), torch.dequantize(CONSTANTS.c293))
    _711 = torch.alias(ret1320)
    _712 = [_709, _710, 32, 128]
    ret1321 = torch.view(_711, _712)
    _713 = torch.alias(ret1321)
    ret1322 = torch.mul(_708, CONSTANTS.c292)
    ret1323 = torch.quantize_per_tensor(torch.alias(ret1322), 0.016428142786026001, 116, 13)
    ret1324 = torch.dequantize(torch.alias(ret1323))
    ret1325 = torch.linear(torch.alias(ret1324), torch.dequantize(CONSTANTS.c294))
    ret1326 = torch.view(torch.alias(ret1325), _712)
    _714 = torch.alias(ret1326)
    ret1327 = torch.mul(_708, CONSTANTS.c292)
    ret1328 = torch.quantize_per_tensor(torch.alias(ret1327), 0.016428142786026001, 116, 13)
    ret1329 = torch.dequantize(torch.alias(ret1328))
    ret1330 = torch.linear(torch.alias(ret1329), torch.dequantize(CONSTANTS.c295))
    ret1331 = torch.view(torch.alias(ret1330), _712)
    _715 = torch.alias(ret1331)
    _716 = torch.contiguous(_692)
    _717 = torch.contiguous(_714)
    _718 = torch.contiguous(_713)
    ops.torch_ipex.rotary_position_embedding(_717, CONSTANTS.c9, _716, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_718, CONSTANTS.c9, _716, 32, 128, 64, 128)
    _719 = torch.contiguous(_122)
    _720 = torch.contiguous(_123)
    _721 = torch.contiguous(_124)
    _722 = torch.contiguous(_125)
    ret1332 = torch.select(_722, 0, 0)
    ret1333, ret1334, ret1335, ret1336, ret1337 = ops.torch_ipex.masked_multihead_self_attention(_718, _717, _715, _719, _720, _721, torch.alias(ret1332), 11.313708498984761, 64, None, _178)
    _723 = torch.alias(ret1333)
    _724 = torch.alias(ret1335)
    _725 = torch.alias(ret1336)
    _726 = torch.alias(ret1337)
    ret1338 = ops.prim.NumToTensor(torch.size(_718, 1))
    ret1339 = torch.add(_722, torch.alias(ret1338))
    _727 = torch.to(torch.alias(ret1339), torch.device("cpu"), 4, False, True)
    ret1340 = torch.transpose(_723, 1, 2)
    ret1341 = torch.reshape(torch.alias(ret1340), [_709, _710, 4096])
    ret1342 = torch.mul(torch.alias(ret1341), CONSTANTS.c296)
    ret1343 = torch.quantize_per_tensor(torch.alias(ret1342), 0.0070910188369452953, 103, 13)
    ret1344 = torch.dequantize(torch.alias(ret1343))
    ret1345 = torch.linear(torch.alias(ret1344), torch.dequantize(CONSTANTS.c297))
    ret1346 = torch.add(_707, torch.alias(ret1345))
    _728 = torch.to(torch.alias(ret1346), 6)
    ret1347 = torch.pow(_728, 2)
    ret1348 = torch.mean(torch.alias(ret1347), [-1], True)
    ret1349 = torch.add(torch.alias(ret1348), CONSTANTS.c3)
    ret1350 = torch.rsqrt(torch.alias(ret1349))
    ret1351 = torch.mul(_728, torch.alias(ret1350))
    ret1352 = torch.mul(CONSTANTS.c298, torch.alias(ret1351))
    _729 = torch.alias(ret1352)
    ret1353 = torch.mul(_729, CONSTANTS.c299)
    ret1354 = torch.quantize_per_tensor(torch.alias(ret1353), 0.0085974419489502907, 150, 13)
    ret1355 = torch.dequantize(torch.alias(ret1354))
    ret1356 = torch.linear(torch.alias(ret1355), torch.dequantize(CONSTANTS.c300))
    input22 = torch.alias(ret1356)
    ret1357 = torch.silu(input22)
    _730 = torch.alias(ret1357)
    ret1358 = torch.mul(_729, CONSTANTS.c299)
    ret1359 = torch.quantize_per_tensor(torch.alias(ret1358), 0.0085974419489502907, 150, 13)
    ret1360 = torch.dequantize(torch.alias(ret1359))
    ret1361 = torch.linear(torch.alias(ret1360), torch.dequantize(CONSTANTS.c301))
    ret1362 = torch.mul(_730, torch.alias(ret1361))
    ret1363 = torch.mul(torch.alias(ret1362), CONSTANTS.c302)
    ret1364 = torch.quantize_per_tensor(torch.alias(ret1363), 0.010936041362583637, 125, 13)
    ret1365 = torch.dequantize(torch.alias(ret1364))
    ret1366 = torch.linear(torch.alias(ret1365), torch.dequantize(CONSTANTS.c303))
    ret1367 = torch.add(_728, torch.alias(ret1366))
    _731 = torch.to(torch.alias(ret1367), 6)
    ret1368 = torch.pow(_731, 2)
    ret1369 = torch.mean(torch.alias(ret1368), [-1], True)
    ret1370 = torch.add(torch.alias(ret1369), CONSTANTS.c3)
    ret1371 = torch.rsqrt(torch.alias(ret1370))
    ret1372 = torch.mul(_731, torch.alias(ret1371))
    ret1373 = torch.mul(CONSTANTS.c304, torch.alias(ret1372))
    _732 = torch.alias(ret1373)
    ret1374 = ops.prim.NumToTensor(torch.size(_732, 0))
    ret1375 = ops.prim.NumToTensor(torch.size(_732, 1))
    _733 = int(torch.alias(ret1374))
    _734 = int(torch.alias(ret1375))
    ret1376 = torch.mul(_732, CONSTANTS.c305)
    ret1377 = torch.quantize_per_tensor(torch.alias(ret1376), 0.016102099791169167, 121, 13)
    ret1378 = torch.dequantize(torch.alias(ret1377))
    ret1379 = torch.linear(torch.alias(ret1378), torch.dequantize(CONSTANTS.c306))
    _735 = torch.alias(ret1379)
    _736 = [_733, _734, 32, 128]
    ret1380 = torch.view(_735, _736)
    _737 = torch.alias(ret1380)
    ret1381 = torch.mul(_732, CONSTANTS.c305)
    ret1382 = torch.quantize_per_tensor(torch.alias(ret1381), 0.016102099791169167, 121, 13)
    ret1383 = torch.dequantize(torch.alias(ret1382))
    ret1384 = torch.linear(torch.alias(ret1383), torch.dequantize(CONSTANTS.c307))
    ret1385 = torch.view(torch.alias(ret1384), _736)
    _738 = torch.alias(ret1385)
    ret1386 = torch.mul(_732, CONSTANTS.c305)
    ret1387 = torch.quantize_per_tensor(torch.alias(ret1386), 0.016102099791169167, 121, 13)
    ret1388 = torch.dequantize(torch.alias(ret1387))
    ret1389 = torch.linear(torch.alias(ret1388), torch.dequantize(CONSTANTS.c308))
    ret1390 = torch.view(torch.alias(ret1389), _736)
    _739 = torch.alias(ret1390)
    _740 = torch.contiguous(_716)
    _741 = torch.contiguous(_738)
    _742 = torch.contiguous(_737)
    ops.torch_ipex.rotary_position_embedding(_741, CONSTANTS.c9, _740, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_742, CONSTANTS.c9, _740, 32, 128, 64, 128)
    _743 = torch.contiguous(_126)
    _744 = torch.contiguous(_127)
    _745 = torch.contiguous(_128)
    _746 = torch.contiguous(_129)
    ret1391 = torch.select(_746, 0, 0)
    ret1392, ret1393, ret1394, ret1395, ret1396 = ops.torch_ipex.masked_multihead_self_attention(_742, _741, _739, _743, _744, _745, torch.alias(ret1391), 11.313708498984761, 64, None, _178)
    _747 = torch.alias(ret1392)
    _748 = torch.alias(ret1394)
    _749 = torch.alias(ret1395)
    _750 = torch.alias(ret1396)
    ret1397 = ops.prim.NumToTensor(torch.size(_742, 1))
    ret1398 = torch.add(_746, torch.alias(ret1397))
    _751 = torch.to(torch.alias(ret1398), torch.device("cpu"), 4, False, True)
    ret1399 = torch.transpose(_747, 1, 2)
    ret1400 = torch.reshape(torch.alias(ret1399), [_733, _734, 4096])
    ret1401 = torch.mul(torch.alias(ret1400), CONSTANTS.c309)
    ret1402 = torch.quantize_per_tensor(torch.alias(ret1401), 0.0073097078129649162, 122, 13)
    ret1403 = torch.dequantize(torch.alias(ret1402))
    ret1404 = torch.linear(torch.alias(ret1403), torch.dequantize(CONSTANTS.c310))
    ret1405 = torch.add(_731, torch.alias(ret1404))
    _752 = torch.to(torch.alias(ret1405), 6)
    ret1406 = torch.pow(_752, 2)
    ret1407 = torch.mean(torch.alias(ret1406), [-1], True)
    ret1408 = torch.add(torch.alias(ret1407), CONSTANTS.c3)
    ret1409 = torch.rsqrt(torch.alias(ret1408))
    ret1410 = torch.mul(_752, torch.alias(ret1409))
    ret1411 = torch.mul(CONSTANTS.c311, torch.alias(ret1410))
    _753 = torch.alias(ret1411)
    ret1412 = torch.mul(_753, CONSTANTS.c312)
    ret1413 = torch.quantize_per_tensor(torch.alias(ret1412), 0.0085814036428928375, 129, 13)
    ret1414 = torch.dequantize(torch.alias(ret1413))
    ret1415 = torch.linear(torch.alias(ret1414), torch.dequantize(CONSTANTS.c313))
    input23 = torch.alias(ret1415)
    ret1416 = torch.silu(input23)
    _754 = torch.alias(ret1416)
    ret1417 = torch.mul(_753, CONSTANTS.c312)
    ret1418 = torch.quantize_per_tensor(torch.alias(ret1417), 0.0085814036428928375, 129, 13)
    ret1419 = torch.dequantize(torch.alias(ret1418))
    ret1420 = torch.linear(torch.alias(ret1419), torch.dequantize(CONSTANTS.c314))
    ret1421 = torch.mul(_754, torch.alias(ret1420))
    ret1422 = torch.mul(torch.alias(ret1421), CONSTANTS.c315)
    ret1423 = torch.quantize_per_tensor(torch.alias(ret1422), 0.014720684848725796, 93, 13)
    ret1424 = torch.dequantize(torch.alias(ret1423))
    ret1425 = torch.linear(torch.alias(ret1424), torch.dequantize(CONSTANTS.c316))
    ret1426 = torch.add(_752, torch.alias(ret1425))
    _755 = torch.to(torch.alias(ret1426), 6)
    ret1427 = torch.pow(_755, 2)
    ret1428 = torch.mean(torch.alias(ret1427), [-1], True)
    ret1429 = torch.add(torch.alias(ret1428), CONSTANTS.c3)
    ret1430 = torch.rsqrt(torch.alias(ret1429))
    ret1431 = torch.mul(_755, torch.alias(ret1430))
    ret1432 = torch.mul(CONSTANTS.c317, torch.alias(ret1431))
    _756 = torch.alias(ret1432)
    ret1433 = ops.prim.NumToTensor(torch.size(_756, 0))
    ret1434 = ops.prim.NumToTensor(torch.size(_756, 1))
    _757 = int(torch.alias(ret1433))
    _758 = int(torch.alias(ret1434))
    ret1435 = torch.mul(_756, CONSTANTS.c318)
    ret1436 = torch.quantize_per_tensor(torch.alias(ret1435), 0.017972579225897789, 114, 13)
    ret1437 = torch.dequantize(torch.alias(ret1436))
    ret1438 = torch.linear(torch.alias(ret1437), torch.dequantize(CONSTANTS.c319))
    _759 = torch.alias(ret1438)
    _760 = [_757, _758, 32, 128]
    ret1439 = torch.view(_759, _760)
    _761 = torch.alias(ret1439)
    ret1440 = torch.mul(_756, CONSTANTS.c318)
    ret1441 = torch.quantize_per_tensor(torch.alias(ret1440), 0.017972579225897789, 114, 13)
    ret1442 = torch.dequantize(torch.alias(ret1441))
    ret1443 = torch.linear(torch.alias(ret1442), torch.dequantize(CONSTANTS.c320))
    ret1444 = torch.view(torch.alias(ret1443), _760)
    _762 = torch.alias(ret1444)
    ret1445 = torch.mul(_756, CONSTANTS.c318)
    ret1446 = torch.quantize_per_tensor(torch.alias(ret1445), 0.017972579225897789, 114, 13)
    ret1447 = torch.dequantize(torch.alias(ret1446))
    ret1448 = torch.linear(torch.alias(ret1447), torch.dequantize(CONSTANTS.c321))
    ret1449 = torch.view(torch.alias(ret1448), _760)
    _763 = torch.alias(ret1449)
    _764 = torch.contiguous(_740)
    _765 = torch.contiguous(_762)
    _766 = torch.contiguous(_761)
    ops.torch_ipex.rotary_position_embedding(_765, CONSTANTS.c9, _764, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_766, CONSTANTS.c9, _764, 32, 128, 64, 128)
    _767 = torch.contiguous(_130)
    _768 = torch.contiguous(_131)
    _769 = torch.contiguous(_132)
    _770 = torch.contiguous(_133)
    ret1450 = torch.select(_770, 0, 0)
    ret1451, ret1452, ret1453, ret1454, ret1455 = ops.torch_ipex.masked_multihead_self_attention(_766, _765, _763, _767, _768, _769, torch.alias(ret1450), 11.313708498984761, 64, None, _178)
    _771 = torch.alias(ret1451)
    _772 = torch.alias(ret1453)
    _773 = torch.alias(ret1454)
    _774 = torch.alias(ret1455)
    ret1456 = ops.prim.NumToTensor(torch.size(_766, 1))
    ret1457 = torch.add(_770, torch.alias(ret1456))
    _775 = torch.to(torch.alias(ret1457), torch.device("cpu"), 4, False, True)
    ret1458 = torch.transpose(_771, 1, 2)
    ret1459 = torch.reshape(torch.alias(ret1458), [_757, _758, 4096])
    ret1460 = torch.mul(torch.alias(ret1459), CONSTANTS.c322)
    ret1461 = torch.quantize_per_tensor(torch.alias(ret1460), 0.010002914816141129, 141, 13)
    ret1462 = torch.dequantize(torch.alias(ret1461))
    ret1463 = torch.linear(torch.alias(ret1462), torch.dequantize(CONSTANTS.c323))
    ret1464 = torch.add(_755, torch.alias(ret1463))
    _776 = torch.to(torch.alias(ret1464), 6)
    ret1465 = torch.pow(_776, 2)
    ret1466 = torch.mean(torch.alias(ret1465), [-1], True)
    ret1467 = torch.add(torch.alias(ret1466), CONSTANTS.c3)
    ret1468 = torch.rsqrt(torch.alias(ret1467))
    ret1469 = torch.mul(_776, torch.alias(ret1468))
    ret1470 = torch.mul(CONSTANTS.c324, torch.alias(ret1469))
    _777 = torch.alias(ret1470)
    ret1471 = torch.mul(_777, CONSTANTS.c325)
    ret1472 = torch.quantize_per_tensor(torch.alias(ret1471), 0.0068971100263297558, 138, 13)
    ret1473 = torch.dequantize(torch.alias(ret1472))
    ret1474 = torch.linear(torch.alias(ret1473), torch.dequantize(CONSTANTS.c326))
    input24 = torch.alias(ret1474)
    ret1475 = torch.silu(input24)
    _778 = torch.alias(ret1475)
    ret1476 = torch.mul(_777, CONSTANTS.c325)
    ret1477 = torch.quantize_per_tensor(torch.alias(ret1476), 0.0068971100263297558, 138, 13)
    ret1478 = torch.dequantize(torch.alias(ret1477))
    ret1479 = torch.linear(torch.alias(ret1478), torch.dequantize(CONSTANTS.c327))
    ret1480 = torch.mul(_778, torch.alias(ret1479))
    ret1481 = torch.mul(torch.alias(ret1480), CONSTANTS.c328)
    ret1482 = torch.quantize_per_tensor(torch.alias(ret1481), 0.01220432948321104, 135, 13)
    ret1483 = torch.dequantize(torch.alias(ret1482))
    ret1484 = torch.linear(torch.alias(ret1483), torch.dequantize(CONSTANTS.c329))
    ret1485 = torch.add(_776, torch.alias(ret1484))
    _779 = torch.to(torch.alias(ret1485), 6)
    ret1486 = torch.pow(_779, 2)
    ret1487 = torch.mean(torch.alias(ret1486), [-1], True)
    ret1488 = torch.add(torch.alias(ret1487), CONSTANTS.c3)
    ret1489 = torch.rsqrt(torch.alias(ret1488))
    ret1490 = torch.mul(_779, torch.alias(ret1489))
    ret1491 = torch.mul(CONSTANTS.c330, torch.alias(ret1490))
    _780 = torch.alias(ret1491)
    ret1492 = ops.prim.NumToTensor(torch.size(_780, 0))
    ret1493 = ops.prim.NumToTensor(torch.size(_780, 1))
    _781 = int(torch.alias(ret1492))
    _782 = int(torch.alias(ret1493))
    ret1494 = torch.mul(_780, CONSTANTS.c331)
    ret1495 = torch.quantize_per_tensor(torch.alias(ret1494), 0.015721969306468964, 121, 13)
    ret1496 = torch.dequantize(torch.alias(ret1495))
    ret1497 = torch.linear(torch.alias(ret1496), torch.dequantize(CONSTANTS.c332))
    _783 = torch.alias(ret1497)
    _784 = [_781, _782, 32, 128]
    ret1498 = torch.view(_783, _784)
    _785 = torch.alias(ret1498)
    ret1499 = torch.mul(_780, CONSTANTS.c331)
    ret1500 = torch.quantize_per_tensor(torch.alias(ret1499), 0.015721969306468964, 121, 13)
    ret1501 = torch.dequantize(torch.alias(ret1500))
    ret1502 = torch.linear(torch.alias(ret1501), torch.dequantize(CONSTANTS.c333))
    ret1503 = torch.view(torch.alias(ret1502), _784)
    _786 = torch.alias(ret1503)
    ret1504 = torch.mul(_780, CONSTANTS.c331)
    ret1505 = torch.quantize_per_tensor(torch.alias(ret1504), 0.015721969306468964, 121, 13)
    ret1506 = torch.dequantize(torch.alias(ret1505))
    ret1507 = torch.linear(torch.alias(ret1506), torch.dequantize(CONSTANTS.c334))
    ret1508 = torch.view(torch.alias(ret1507), _784)
    _787 = torch.alias(ret1508)
    _788 = torch.contiguous(_764)
    _789 = torch.contiguous(_786)
    _790 = torch.contiguous(_785)
    ops.torch_ipex.rotary_position_embedding(_789, CONSTANTS.c9, _788, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_790, CONSTANTS.c9, _788, 32, 128, 64, 128)
    _791 = torch.contiguous(_134)
    _792 = torch.contiguous(_135)
    _793 = torch.contiguous(_136)
    _794 = torch.contiguous(_137)
    ret1509 = torch.select(_794, 0, 0)
    ret1510, ret1511, ret1512, ret1513, ret1514 = ops.torch_ipex.masked_multihead_self_attention(_790, _789, _787, _791, _792, _793, torch.alias(ret1509), 11.313708498984761, 64, None, _178)
    _795 = torch.alias(ret1510)
    _796 = torch.alias(ret1512)
    _797 = torch.alias(ret1513)
    _798 = torch.alias(ret1514)
    ret1515 = ops.prim.NumToTensor(torch.size(_790, 1))
    ret1516 = torch.add(_794, torch.alias(ret1515))
    _799 = torch.to(torch.alias(ret1516), torch.device("cpu"), 4, False, True)
    ret1517 = torch.transpose(_795, 1, 2)
    ret1518 = torch.reshape(torch.alias(ret1517), [_781, _782, 4096])
    ret1519 = torch.mul(torch.alias(ret1518), CONSTANTS.c335)
    ret1520 = torch.quantize_per_tensor(torch.alias(ret1519), 0.0075003970414400101, 131, 13)
    ret1521 = torch.dequantize(torch.alias(ret1520))
    ret1522 = torch.linear(torch.alias(ret1521), torch.dequantize(CONSTANTS.c336))
    ret1523 = torch.add(_779, torch.alias(ret1522))
    _800 = torch.to(torch.alias(ret1523), 6)
    ret1524 = torch.pow(_800, 2)
    ret1525 = torch.mean(torch.alias(ret1524), [-1], True)
    ret1526 = torch.add(torch.alias(ret1525), CONSTANTS.c3)
    ret1527 = torch.rsqrt(torch.alias(ret1526))
    ret1528 = torch.mul(_800, torch.alias(ret1527))
    ret1529 = torch.mul(CONSTANTS.c337, torch.alias(ret1528))
    _801 = torch.alias(ret1529)
    ret1530 = torch.mul(_801, CONSTANTS.c338)
    ret1531 = torch.quantize_per_tensor(torch.alias(ret1530), 0.0095560634508728981, 137, 13)
    ret1532 = torch.dequantize(torch.alias(ret1531))
    ret1533 = torch.linear(torch.alias(ret1532), torch.dequantize(CONSTANTS.c339))
    input25 = torch.alias(ret1533)
    ret1534 = torch.silu(input25)
    _802 = torch.alias(ret1534)
    ret1535 = torch.mul(_801, CONSTANTS.c338)
    ret1536 = torch.quantize_per_tensor(torch.alias(ret1535), 0.0095560634508728981, 137, 13)
    ret1537 = torch.dequantize(torch.alias(ret1536))
    ret1538 = torch.linear(torch.alias(ret1537), torch.dequantize(CONSTANTS.c340))
    ret1539 = torch.mul(_802, torch.alias(ret1538))
    ret1540 = torch.mul(torch.alias(ret1539), CONSTANTS.c341)
    ret1541 = torch.quantize_per_tensor(torch.alias(ret1540), 0.018062291666865349, 95, 13)
    ret1542 = torch.dequantize(torch.alias(ret1541))
    ret1543 = torch.linear(torch.alias(ret1542), torch.dequantize(CONSTANTS.c342))
    ret1544 = torch.add(_800, torch.alias(ret1543))
    _803 = torch.to(torch.alias(ret1544), 6)
    ret1545 = torch.pow(_803, 2)
    ret1546 = torch.mean(torch.alias(ret1545), [-1], True)
    ret1547 = torch.add(torch.alias(ret1546), CONSTANTS.c3)
    ret1548 = torch.rsqrt(torch.alias(ret1547))
    ret1549 = torch.mul(_803, torch.alias(ret1548))
    ret1550 = torch.mul(CONSTANTS.c343, torch.alias(ret1549))
    _804 = torch.alias(ret1550)
    ret1551 = ops.prim.NumToTensor(torch.size(_804, 0))
    ret1552 = ops.prim.NumToTensor(torch.size(_804, 1))
    _805 = int(torch.alias(ret1551))
    _806 = int(torch.alias(ret1552))
    ret1553 = torch.mul(_804, CONSTANTS.c344)
    ret1554 = torch.quantize_per_tensor(torch.alias(ret1553), 0.018108947202563286, 119, 13)
    ret1555 = torch.dequantize(torch.alias(ret1554))
    ret1556 = torch.linear(torch.alias(ret1555), torch.dequantize(CONSTANTS.c345))
    _807 = torch.alias(ret1556)
    _808 = [_805, _806, 32, 128]
    ret1557 = torch.view(_807, _808)
    _809 = torch.alias(ret1557)
    ret1558 = torch.mul(_804, CONSTANTS.c344)
    ret1559 = torch.quantize_per_tensor(torch.alias(ret1558), 0.018108947202563286, 119, 13)
    ret1560 = torch.dequantize(torch.alias(ret1559))
    ret1561 = torch.linear(torch.alias(ret1560), torch.dequantize(CONSTANTS.c346))
    ret1562 = torch.view(torch.alias(ret1561), _808)
    _810 = torch.alias(ret1562)
    ret1563 = torch.mul(_804, CONSTANTS.c344)
    ret1564 = torch.quantize_per_tensor(torch.alias(ret1563), 0.018108947202563286, 119, 13)
    ret1565 = torch.dequantize(torch.alias(ret1564))
    ret1566 = torch.linear(torch.alias(ret1565), torch.dequantize(CONSTANTS.c347))
    ret1567 = torch.view(torch.alias(ret1566), _808)
    _811 = torch.alias(ret1567)
    _812 = torch.contiguous(_788)
    _813 = torch.contiguous(_810)
    _814 = torch.contiguous(_809)
    ops.torch_ipex.rotary_position_embedding(_813, CONSTANTS.c9, _812, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_814, CONSTANTS.c9, _812, 32, 128, 64, 128)
    _815 = torch.contiguous(_138)
    _816 = torch.contiguous(_139)
    _817 = torch.contiguous(_140)
    _818 = torch.contiguous(_141)
    ret1568 = torch.select(_818, 0, 0)
    ret1569, ret1570, ret1571, ret1572, ret1573 = ops.torch_ipex.masked_multihead_self_attention(_814, _813, _811, _815, _816, _817, torch.alias(ret1568), 11.313708498984761, 64, None, _178)
    _819 = torch.alias(ret1569)
    _820 = torch.alias(ret1571)
    _821 = torch.alias(ret1572)
    _822 = torch.alias(ret1573)
    ret1574 = ops.prim.NumToTensor(torch.size(_814, 1))
    ret1575 = torch.add(_818, torch.alias(ret1574))
    _823 = torch.to(torch.alias(ret1575), torch.device("cpu"), 4, False, True)
    ret1576 = torch.transpose(_819, 1, 2)
    ret1577 = torch.reshape(torch.alias(ret1576), [_805, _806, 4096])
    ret1578 = torch.mul(torch.alias(ret1577), CONSTANTS.c348)
    ret1579 = torch.quantize_per_tensor(torch.alias(ret1578), 0.0085107013583183289, 118, 13)
    ret1580 = torch.dequantize(torch.alias(ret1579))
    ret1581 = torch.linear(torch.alias(ret1580), torch.dequantize(CONSTANTS.c349))
    ret1582 = torch.add(_803, torch.alias(ret1581))
    _824 = torch.to(torch.alias(ret1582), 6)
    ret1583 = torch.pow(_824, 2)
    ret1584 = torch.mean(torch.alias(ret1583), [-1], True)
    ret1585 = torch.add(torch.alias(ret1584), CONSTANTS.c3)
    ret1586 = torch.rsqrt(torch.alias(ret1585))
    ret1587 = torch.mul(_824, torch.alias(ret1586))
    ret1588 = torch.mul(CONSTANTS.c350, torch.alias(ret1587))
    _825 = torch.alias(ret1588)
    ret1589 = torch.mul(_825, CONSTANTS.c351)
    ret1590 = torch.quantize_per_tensor(torch.alias(ret1589), 0.0084043014794588089, 135, 13)
    ret1591 = torch.dequantize(torch.alias(ret1590))
    ret1592 = torch.linear(torch.alias(ret1591), torch.dequantize(CONSTANTS.c352))
    input26 = torch.alias(ret1592)
    ret1593 = torch.silu(input26)
    _826 = torch.alias(ret1593)
    ret1594 = torch.mul(_825, CONSTANTS.c351)
    ret1595 = torch.quantize_per_tensor(torch.alias(ret1594), 0.0084043014794588089, 135, 13)
    ret1596 = torch.dequantize(torch.alias(ret1595))
    ret1597 = torch.linear(torch.alias(ret1596), torch.dequantize(CONSTANTS.c353))
    ret1598 = torch.mul(_826, torch.alias(ret1597))
    ret1599 = torch.mul(torch.alias(ret1598), CONSTANTS.c354)
    ret1600 = torch.quantize_per_tensor(torch.alias(ret1599), 0.011481082998216152, 124, 13)
    ret1601 = torch.dequantize(torch.alias(ret1600))
    ret1602 = torch.linear(torch.alias(ret1601), torch.dequantize(CONSTANTS.c355))
    ret1603 = torch.add(_824, torch.alias(ret1602))
    _827 = torch.to(torch.alias(ret1603), 6)
    ret1604 = torch.pow(_827, 2)
    ret1605 = torch.mean(torch.alias(ret1604), [-1], True)
    ret1606 = torch.add(torch.alias(ret1605), CONSTANTS.c3)
    ret1607 = torch.rsqrt(torch.alias(ret1606))
    ret1608 = torch.mul(_827, torch.alias(ret1607))
    ret1609 = torch.mul(CONSTANTS.c356, torch.alias(ret1608))
    _828 = torch.alias(ret1609)
    ret1610 = ops.prim.NumToTensor(torch.size(_828, 0))
    ret1611 = ops.prim.NumToTensor(torch.size(_828, 1))
    _829 = int(torch.alias(ret1610))
    _830 = int(torch.alias(ret1611))
    ret1612 = torch.mul(_828, CONSTANTS.c357)
    ret1613 = torch.quantize_per_tensor(torch.alias(ret1612), 0.015004269778728485, 111, 13)
    ret1614 = torch.dequantize(torch.alias(ret1613))
    ret1615 = torch.linear(torch.alias(ret1614), torch.dequantize(CONSTANTS.c358))
    _831 = torch.alias(ret1615)
    _832 = [_829, _830, 32, 128]
    ret1616 = torch.view(_831, _832)
    _833 = torch.alias(ret1616)
    ret1617 = torch.mul(_828, CONSTANTS.c357)
    ret1618 = torch.quantize_per_tensor(torch.alias(ret1617), 0.015004269778728485, 111, 13)
    ret1619 = torch.dequantize(torch.alias(ret1618))
    ret1620 = torch.linear(torch.alias(ret1619), torch.dequantize(CONSTANTS.c359))
    ret1621 = torch.view(torch.alias(ret1620), _832)
    _834 = torch.alias(ret1621)
    ret1622 = torch.mul(_828, CONSTANTS.c357)
    ret1623 = torch.quantize_per_tensor(torch.alias(ret1622), 0.015004269778728485, 111, 13)
    ret1624 = torch.dequantize(torch.alias(ret1623))
    ret1625 = torch.linear(torch.alias(ret1624), torch.dequantize(CONSTANTS.c360))
    ret1626 = torch.view(torch.alias(ret1625), _832)
    _835 = torch.alias(ret1626)
    _836 = torch.contiguous(_812)
    _837 = torch.contiguous(_834)
    _838 = torch.contiguous(_833)
    ops.torch_ipex.rotary_position_embedding(_837, CONSTANTS.c9, _836, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_838, CONSTANTS.c9, _836, 32, 128, 64, 128)
    _839 = torch.contiguous(_142)
    _840 = torch.contiguous(_143)
    _841 = torch.contiguous(_144)
    _842 = torch.contiguous(_145)
    ret1627 = torch.select(_842, 0, 0)
    ret1628, ret1629, ret1630, ret1631, ret1632 = ops.torch_ipex.masked_multihead_self_attention(_838, _837, _835, _839, _840, _841, torch.alias(ret1627), 11.313708498984761, 64, None, _178)
    _843 = torch.alias(ret1628)
    _844 = torch.alias(ret1630)
    _845 = torch.alias(ret1631)
    _846 = torch.alias(ret1632)
    ret1633 = ops.prim.NumToTensor(torch.size(_838, 1))
    ret1634 = torch.add(_842, torch.alias(ret1633))
    _847 = torch.to(torch.alias(ret1634), torch.device("cpu"), 4, False, True)
    ret1635 = torch.transpose(_843, 1, 2)
    ret1636 = torch.reshape(torch.alias(ret1635), [_829, _830, 4096])
    ret1637 = torch.mul(torch.alias(ret1636), CONSTANTS.c361)
    ret1638 = torch.quantize_per_tensor(torch.alias(ret1637), 0.010986634530127048, 153, 13)
    ret1639 = torch.dequantize(torch.alias(ret1638))
    ret1640 = torch.linear(torch.alias(ret1639), torch.dequantize(CONSTANTS.c362))
    ret1641 = torch.add(_827, torch.alias(ret1640))
    _848 = torch.to(torch.alias(ret1641), 6)
    ret1642 = torch.pow(_848, 2)
    ret1643 = torch.mean(torch.alias(ret1642), [-1], True)
    ret1644 = torch.add(torch.alias(ret1643), CONSTANTS.c3)
    ret1645 = torch.rsqrt(torch.alias(ret1644))
    ret1646 = torch.mul(_848, torch.alias(ret1645))
    ret1647 = torch.mul(CONSTANTS.c363, torch.alias(ret1646))
    _849 = torch.alias(ret1647)
    ret1648 = torch.mul(_849, CONSTANTS.c364)
    ret1649 = torch.quantize_per_tensor(torch.alias(ret1648), 0.010858063586056232, 115, 13)
    ret1650 = torch.dequantize(torch.alias(ret1649))
    ret1651 = torch.linear(torch.alias(ret1650), torch.dequantize(CONSTANTS.c365))
    input27 = torch.alias(ret1651)
    ret1652 = torch.silu(input27)
    _850 = torch.alias(ret1652)
    ret1653 = torch.mul(_849, CONSTANTS.c364)
    ret1654 = torch.quantize_per_tensor(torch.alias(ret1653), 0.010858063586056232, 115, 13)
    ret1655 = torch.dequantize(torch.alias(ret1654))
    ret1656 = torch.linear(torch.alias(ret1655), torch.dequantize(CONSTANTS.c366))
    ret1657 = torch.mul(_850, torch.alias(ret1656))
    ret1658 = torch.mul(torch.alias(ret1657), CONSTANTS.c367)
    ret1659 = torch.quantize_per_tensor(torch.alias(ret1658), 0.01497429795563221, 103, 13)
    ret1660 = torch.dequantize(torch.alias(ret1659))
    ret1661 = torch.linear(torch.alias(ret1660), torch.dequantize(CONSTANTS.c368))
    ret1662 = torch.add(_848, torch.alias(ret1661))
    _851 = torch.to(torch.alias(ret1662), 6)
    ret1663 = torch.pow(_851, 2)
    ret1664 = torch.mean(torch.alias(ret1663), [-1], True)
    ret1665 = torch.add(torch.alias(ret1664), CONSTANTS.c3)
    ret1666 = torch.rsqrt(torch.alias(ret1665))
    ret1667 = torch.mul(_851, torch.alias(ret1666))
    ret1668 = torch.mul(CONSTANTS.c369, torch.alias(ret1667))
    _852 = torch.alias(ret1668)
    ret1669 = ops.prim.NumToTensor(torch.size(_852, 0))
    ret1670 = ops.prim.NumToTensor(torch.size(_852, 1))
    _853 = int(torch.alias(ret1669))
    _854 = int(torch.alias(ret1670))
    ret1671 = torch.mul(_852, CONSTANTS.c370)
    ret1672 = torch.quantize_per_tensor(torch.alias(ret1671), 0.016707412898540497, 124, 13)
    ret1673 = torch.dequantize(torch.alias(ret1672))
    ret1674 = torch.linear(torch.alias(ret1673), torch.dequantize(CONSTANTS.c371))
    _855 = torch.alias(ret1674)
    _856 = [_853, _854, 32, 128]
    ret1675 = torch.view(_855, _856)
    _857 = torch.alias(ret1675)
    ret1676 = torch.mul(_852, CONSTANTS.c370)
    ret1677 = torch.quantize_per_tensor(torch.alias(ret1676), 0.016707412898540497, 124, 13)
    ret1678 = torch.dequantize(torch.alias(ret1677))
    ret1679 = torch.linear(torch.alias(ret1678), torch.dequantize(CONSTANTS.c372))
    ret1680 = torch.view(torch.alias(ret1679), _856)
    _858 = torch.alias(ret1680)
    ret1681 = torch.mul(_852, CONSTANTS.c370)
    ret1682 = torch.quantize_per_tensor(torch.alias(ret1681), 0.016707412898540497, 124, 13)
    ret1683 = torch.dequantize(torch.alias(ret1682))
    ret1684 = torch.linear(torch.alias(ret1683), torch.dequantize(CONSTANTS.c373))
    ret1685 = torch.view(torch.alias(ret1684), _856)
    _859 = torch.alias(ret1685)
    _860 = torch.contiguous(_836)
    _861 = torch.contiguous(_858)
    _862 = torch.contiguous(_857)
    ops.torch_ipex.rotary_position_embedding(_861, CONSTANTS.c9, _860, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_862, CONSTANTS.c9, _860, 32, 128, 64, 128)
    _863 = torch.contiguous(_146)
    _864 = torch.contiguous(_147)
    _865 = torch.contiguous(_148)
    _866 = torch.contiguous(_149)
    ret1686 = torch.select(_866, 0, 0)
    ret1687, ret1688, ret1689, ret1690, ret1691 = ops.torch_ipex.masked_multihead_self_attention(_862, _861, _859, _863, _864, _865, torch.alias(ret1686), 11.313708498984761, 64, None, _178)
    _867 = torch.alias(ret1687)
    _868 = torch.alias(ret1689)
    _869 = torch.alias(ret1690)
    _870 = torch.alias(ret1691)
    ret1692 = ops.prim.NumToTensor(torch.size(_862, 1))
    ret1693 = torch.add(_866, torch.alias(ret1692))
    _871 = torch.to(torch.alias(ret1693), torch.device("cpu"), 4, False, True)
    ret1694 = torch.transpose(_867, 1, 2)
    ret1695 = torch.reshape(torch.alias(ret1694), [_853, _854, 4096])
    ret1696 = torch.mul(torch.alias(ret1695), CONSTANTS.c374)
    ret1697 = torch.quantize_per_tensor(torch.alias(ret1696), 0.0097340131178498268, 116, 13)
    ret1698 = torch.dequantize(torch.alias(ret1697))
    ret1699 = torch.linear(torch.alias(ret1698), torch.dequantize(CONSTANTS.c375))
    ret1700 = torch.add(_851, torch.alias(ret1699))
    _872 = torch.to(torch.alias(ret1700), 6)
    ret1701 = torch.pow(_872, 2)
    ret1702 = torch.mean(torch.alias(ret1701), [-1], True)
    ret1703 = torch.add(torch.alias(ret1702), CONSTANTS.c3)
    ret1704 = torch.rsqrt(torch.alias(ret1703))
    ret1705 = torch.mul(_872, torch.alias(ret1704))
    ret1706 = torch.mul(CONSTANTS.c376, torch.alias(ret1705))
    _873 = torch.alias(ret1706)
    ret1707 = torch.mul(_873, CONSTANTS.c377)
    ret1708 = torch.quantize_per_tensor(torch.alias(ret1707), 0.010993242263793945, 133, 13)
    ret1709 = torch.dequantize(torch.alias(ret1708))
    ret1710 = torch.linear(torch.alias(ret1709), torch.dequantize(CONSTANTS.c378))
    input28 = torch.alias(ret1710)
    ret1711 = torch.silu(input28)
    _874 = torch.alias(ret1711)
    ret1712 = torch.mul(_873, CONSTANTS.c377)
    ret1713 = torch.quantize_per_tensor(torch.alias(ret1712), 0.010993242263793945, 133, 13)
    ret1714 = torch.dequantize(torch.alias(ret1713))
    ret1715 = torch.linear(torch.alias(ret1714), torch.dequantize(CONSTANTS.c379))
    ret1716 = torch.mul(_874, torch.alias(ret1715))
    ret1717 = torch.mul(torch.alias(ret1716), CONSTANTS.c380)
    ret1718 = torch.quantize_per_tensor(torch.alias(ret1717), 0.017145805060863495, 142, 13)
    ret1719 = torch.dequantize(torch.alias(ret1718))
    ret1720 = torch.linear(torch.alias(ret1719), torch.dequantize(CONSTANTS.c381))
    ret1721 = torch.add(_872, torch.alias(ret1720))
    _875 = torch.to(torch.alias(ret1721), 6)
    ret1722 = torch.pow(_875, 2)
    ret1723 = torch.mean(torch.alias(ret1722), [-1], True)
    ret1724 = torch.add(torch.alias(ret1723), CONSTANTS.c3)
    ret1725 = torch.rsqrt(torch.alias(ret1724))
    ret1726 = torch.mul(_875, torch.alias(ret1725))
    ret1727 = torch.mul(CONSTANTS.c382, torch.alias(ret1726))
    _876 = torch.alias(ret1727)
    ret1728 = ops.prim.NumToTensor(torch.size(_876, 0))
    ret1729 = ops.prim.NumToTensor(torch.size(_876, 1))
    _877 = int(torch.alias(ret1728))
    _878 = int(torch.alias(ret1729))
    ret1730 = torch.mul(_876, CONSTANTS.c383)
    ret1731 = torch.quantize_per_tensor(torch.alias(ret1730), 0.014413755387067795, 113, 13)
    ret1732 = torch.dequantize(torch.alias(ret1731))
    ret1733 = torch.linear(torch.alias(ret1732), torch.dequantize(CONSTANTS.c384))
    _879 = torch.alias(ret1733)
    _880 = [_877, _878, 32, 128]
    ret1734 = torch.view(_879, _880)
    _881 = torch.alias(ret1734)
    ret1735 = torch.mul(_876, CONSTANTS.c383)
    ret1736 = torch.quantize_per_tensor(torch.alias(ret1735), 0.014413755387067795, 113, 13)
    ret1737 = torch.dequantize(torch.alias(ret1736))
    ret1738 = torch.linear(torch.alias(ret1737), torch.dequantize(CONSTANTS.c385))
    ret1739 = torch.view(torch.alias(ret1738), _880)
    _882 = torch.alias(ret1739)
    ret1740 = torch.mul(_876, CONSTANTS.c383)
    ret1741 = torch.quantize_per_tensor(torch.alias(ret1740), 0.014413755387067795, 113, 13)
    ret1742 = torch.dequantize(torch.alias(ret1741))
    ret1743 = torch.linear(torch.alias(ret1742), torch.dequantize(CONSTANTS.c386))
    ret1744 = torch.view(torch.alias(ret1743), _880)
    _883 = torch.alias(ret1744)
    _884 = torch.contiguous(_860)
    _885 = torch.contiguous(_882)
    _886 = torch.contiguous(_881)
    ops.torch_ipex.rotary_position_embedding(_885, CONSTANTS.c9, _884, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_886, CONSTANTS.c9, _884, 32, 128, 64, 128)
    _887 = torch.contiguous(_150)
    _888 = torch.contiguous(_151)
    _889 = torch.contiguous(_152)
    _890 = torch.contiguous(_153)
    ret1745 = torch.select(_890, 0, 0)
    ret1746, ret1747, ret1748, ret1749, ret1750 = ops.torch_ipex.masked_multihead_self_attention(_886, _885, _883, _887, _888, _889, torch.alias(ret1745), 11.313708498984761, 64, None, _178)
    _891 = torch.alias(ret1746)
    _892 = torch.alias(ret1748)
    _893 = torch.alias(ret1749)
    _894 = torch.alias(ret1750)
    ret1751 = ops.prim.NumToTensor(torch.size(_886, 1))
    ret1752 = torch.add(_890, torch.alias(ret1751))
    _895 = torch.to(torch.alias(ret1752), torch.device("cpu"), 4, False, True)
    ret1753 = torch.transpose(_891, 1, 2)
    ret1754 = torch.reshape(torch.alias(ret1753), [_877, _878, 4096])
    ret1755 = torch.mul(torch.alias(ret1754), CONSTANTS.c387)
    ret1756 = torch.quantize_per_tensor(torch.alias(ret1755), 0.013252421282231808, 130, 13)
    ret1757 = torch.dequantize(torch.alias(ret1756))
    ret1758 = torch.linear(torch.alias(ret1757), torch.dequantize(CONSTANTS.c388))
    ret1759 = torch.add(_875, torch.alias(ret1758))
    _896 = torch.to(torch.alias(ret1759), 6)
    ret1760 = torch.pow(_896, 2)
    ret1761 = torch.mean(torch.alias(ret1760), [-1], True)
    ret1762 = torch.add(torch.alias(ret1761), CONSTANTS.c3)
    ret1763 = torch.rsqrt(torch.alias(ret1762))
    ret1764 = torch.mul(_896, torch.alias(ret1763))
    ret1765 = torch.mul(CONSTANTS.c389, torch.alias(ret1764))
    _897 = torch.alias(ret1765)
    ret1766 = torch.mul(_897, CONSTANTS.c390)
    ret1767 = torch.quantize_per_tensor(torch.alias(ret1766), 0.01358379889279604, 131, 13)
    ret1768 = torch.dequantize(torch.alias(ret1767))
    ret1769 = torch.linear(torch.alias(ret1768), torch.dequantize(CONSTANTS.c391))
    input29 = torch.alias(ret1769)
    ret1770 = torch.silu(input29)
    _898 = torch.alias(ret1770)
    ret1771 = torch.mul(_897, CONSTANTS.c390)
    ret1772 = torch.quantize_per_tensor(torch.alias(ret1771), 0.01358379889279604, 131, 13)
    ret1773 = torch.dequantize(torch.alias(ret1772))
    ret1774 = torch.linear(torch.alias(ret1773), torch.dequantize(CONSTANTS.c392))
    ret1775 = torch.mul(_898, torch.alias(ret1774))
    ret1776 = torch.mul(torch.alias(ret1775), CONSTANTS.c393)
    ret1777 = torch.quantize_per_tensor(torch.alias(ret1776), 0.032335508614778519, 52, 13)
    ret1778 = torch.dequantize(torch.alias(ret1777))
    ret1779 = torch.linear(torch.alias(ret1778), torch.dequantize(CONSTANTS.c394))
    ret1780 = torch.add(_896, torch.alias(ret1779))
    _899 = torch.to(torch.alias(ret1780), 6)
    ret1781 = torch.pow(_899, 2)
    ret1782 = torch.mean(torch.alias(ret1781), [-1], True)
    ret1783 = torch.add(torch.alias(ret1782), CONSTANTS.c3)
    ret1784 = torch.rsqrt(torch.alias(ret1783))
    ret1785 = torch.mul(_899, torch.alias(ret1784))
    ret1786 = torch.mul(CONSTANTS.c395, torch.alias(ret1785))
    _900 = torch.alias(ret1786)
    ret1787 = ops.prim.NumToTensor(torch.size(_900, 0))
    ret1788 = ops.prim.NumToTensor(torch.size(_900, 1))
    _901 = int(torch.alias(ret1787))
    _902 = int(torch.alias(ret1788))
    ret1789 = torch.mul(_900, CONSTANTS.c396)
    ret1790 = torch.quantize_per_tensor(torch.alias(ret1789), 0.017930306494235992, 136, 13)
    ret1791 = torch.dequantize(torch.alias(ret1790))
    ret1792 = torch.linear(torch.alias(ret1791), torch.dequantize(CONSTANTS.c397))
    _903 = torch.alias(ret1792)
    _904 = [_901, _902, 32, 128]
    ret1793 = torch.view(_903, _904)
    _905 = torch.alias(ret1793)
    ret1794 = torch.mul(_900, CONSTANTS.c396)
    ret1795 = torch.quantize_per_tensor(torch.alias(ret1794), 0.017930306494235992, 136, 13)
    ret1796 = torch.dequantize(torch.alias(ret1795))
    ret1797 = torch.linear(torch.alias(ret1796), torch.dequantize(CONSTANTS.c398))
    ret1798 = torch.view(torch.alias(ret1797), _904)
    _906 = torch.alias(ret1798)
    ret1799 = torch.mul(_900, CONSTANTS.c396)
    ret1800 = torch.quantize_per_tensor(torch.alias(ret1799), 0.017930306494235992, 136, 13)
    ret1801 = torch.dequantize(torch.alias(ret1800))
    ret1802 = torch.linear(torch.alias(ret1801), torch.dequantize(CONSTANTS.c399))
    ret1803 = torch.view(torch.alias(ret1802), _904)
    _907 = torch.alias(ret1803)
    _908 = torch.contiguous(_884)
    _909 = torch.contiguous(_906)
    _910 = torch.contiguous(_905)
    ops.torch_ipex.rotary_position_embedding(_909, CONSTANTS.c9, _908, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_910, CONSTANTS.c9, _908, 32, 128, 64, 128)
    _911 = torch.contiguous(_154)
    _912 = torch.contiguous(_155)
    _913 = torch.contiguous(_156)
    _914 = torch.contiguous(_157)
    ret1804 = torch.select(_914, 0, 0)
    ret1805, ret1806, ret1807, ret1808, ret1809 = ops.torch_ipex.masked_multihead_self_attention(_910, _909, _907, _911, _912, _913, torch.alias(ret1804), 11.313708498984761, 64, None, _178)
    _915 = torch.alias(ret1805)
    _916 = torch.alias(ret1807)
    _917 = torch.alias(ret1808)
    _918 = torch.alias(ret1809)
    ret1810 = ops.prim.NumToTensor(torch.size(_910, 1))
    ret1811 = torch.add(_914, torch.alias(ret1810))
    _919 = torch.to(torch.alias(ret1811), torch.device("cpu"), 4, False, True)
    ret1812 = torch.transpose(_915, 1, 2)
    ret1813 = torch.reshape(torch.alias(ret1812), [_901, _902, 4096])
    ret1814 = torch.mul(torch.alias(ret1813), CONSTANTS.c400)
    ret1815 = torch.quantize_per_tensor(torch.alias(ret1814), 0.010694587603211403, 110, 13)
    ret1816 = torch.dequantize(torch.alias(ret1815))
    ret1817 = torch.linear(torch.alias(ret1816), torch.dequantize(CONSTANTS.c401))
    ret1818 = torch.add(_899, torch.alias(ret1817))
    _920 = torch.to(torch.alias(ret1818), 6)
    ret1819 = torch.pow(_920, 2)
    ret1820 = torch.mean(torch.alias(ret1819), [-1], True)
    ret1821 = torch.add(torch.alias(ret1820), CONSTANTS.c3)
    ret1822 = torch.rsqrt(torch.alias(ret1821))
    ret1823 = torch.mul(_920, torch.alias(ret1822))
    ret1824 = torch.mul(CONSTANTS.c402, torch.alias(ret1823))
    _921 = torch.alias(ret1824)
    ret1825 = torch.mul(_921, CONSTANTS.c403)
    ret1826 = torch.quantize_per_tensor(torch.alias(ret1825), 0.017997544258832932, 135, 13)
    ret1827 = torch.dequantize(torch.alias(ret1826))
    ret1828 = torch.linear(torch.alias(ret1827), torch.dequantize(CONSTANTS.c404))
    input30 = torch.alias(ret1828)
    ret1829 = torch.silu(input30)
    _922 = torch.alias(ret1829)
    ret1830 = torch.mul(_921, CONSTANTS.c403)
    ret1831 = torch.quantize_per_tensor(torch.alias(ret1830), 0.017997544258832932, 135, 13)
    ret1832 = torch.dequantize(torch.alias(ret1831))
    ret1833 = torch.linear(torch.alias(ret1832), torch.dequantize(CONSTANTS.c405))
    ret1834 = torch.mul(_922, torch.alias(ret1833))
    ret1835 = torch.mul(torch.alias(ret1834), CONSTANTS.c406)
    ret1836 = torch.quantize_per_tensor(torch.alias(ret1835), 0.21564501523971558, 33, 13)
    ret1837 = torch.dequantize(torch.alias(ret1836))
    ret1838 = torch.linear(torch.alias(ret1837), torch.dequantize(CONSTANTS.c407))
    ret1839 = torch.add(_920, torch.alias(ret1838))
    _923 = torch.to(torch.alias(ret1839), 6)
    ret1840 = torch.pow(_923, 2)
    ret1841 = torch.mean(torch.alias(ret1840), [-1], True)
    ret1842 = torch.add(torch.alias(ret1841), CONSTANTS.c3)
    ret1843 = torch.rsqrt(torch.alias(ret1842))
    ret1844 = torch.mul(_923, torch.alias(ret1843))
    ret1845 = torch.mul(CONSTANTS.c408, torch.alias(ret1844))
    _924 = torch.alias(ret1845)
    ret1846 = ops.prim.NumToTensor(torch.size(_924, 0))
    ret1847 = ops.prim.NumToTensor(torch.size(_924, 1))
    _925 = int(torch.alias(ret1846))
    _926 = int(torch.alias(ret1847))
    ret1848 = torch.mul(_924, CONSTANTS.c409)
    ret1849 = torch.quantize_per_tensor(torch.alias(ret1848), 0.017270715907216072, 122, 13)
    ret1850 = torch.dequantize(torch.alias(ret1849))
    ret1851 = torch.linear(torch.alias(ret1850), torch.dequantize(CONSTANTS.c410))
    _927 = torch.alias(ret1851)
    _928 = [_925, _926, 32, 128]
    ret1852 = torch.view(_927, _928)
    _929 = torch.alias(ret1852)
    ret1853 = torch.mul(_924, CONSTANTS.c409)
    ret1854 = torch.quantize_per_tensor(torch.alias(ret1853), 0.017270715907216072, 122, 13)
    ret1855 = torch.dequantize(torch.alias(ret1854))
    ret1856 = torch.linear(torch.alias(ret1855), torch.dequantize(CONSTANTS.c411))
    ret1857 = torch.view(torch.alias(ret1856), _928)
    _930 = torch.alias(ret1857)
    ret1858 = torch.mul(_924, CONSTANTS.c409)
    ret1859 = torch.quantize_per_tensor(torch.alias(ret1858), 0.017270715907216072, 122, 13)
    ret1860 = torch.dequantize(torch.alias(ret1859))
    ret1861 = torch.linear(torch.alias(ret1860), torch.dequantize(CONSTANTS.c412))
    ret1862 = torch.view(torch.alias(ret1861), _928)
    _931 = torch.alias(ret1862)
    _932 = torch.contiguous(_908)
    _933 = torch.contiguous(_930)
    _934 = torch.contiguous(_929)
    ops.torch_ipex.rotary_position_embedding(_933, CONSTANTS.c9, _932, 32, 128, 64, 128)
    ops.torch_ipex.rotary_position_embedding(_934, CONSTANTS.c9, _932, 32, 128, 64, 128)
    _935 = torch.contiguous(_158)
    _936 = torch.contiguous(_159)
    _937 = torch.contiguous(_160)
    _938 = torch.contiguous(_161)
    ret1863 = torch.select(_938, 0, 0)
    ret1864, ret1865, ret1866, ret1867, ret1868 = ops.torch_ipex.masked_multihead_self_attention(_934, _933, _931, _935, _936, _937, torch.alias(ret1863), 11.313708498984761, 64, None, _178)
    _939 = torch.alias(ret1864)
    _940 = torch.alias(ret1866)
    _941 = torch.alias(ret1867)
    _942 = torch.alias(ret1868)
    ret1869 = ops.prim.NumToTensor(torch.size(_934, 1))
    ret1870 = torch.add(_938, torch.alias(ret1869))
    _943 = torch.to(torch.alias(ret1870), torch.device("cpu"), 4, False, True)
    ret1871 = torch.transpose(_939, 1, 2)
    ret1872 = torch.reshape(torch.alias(ret1871), [_925, _926, 4096])
    ret1873 = torch.mul(torch.alias(ret1872), CONSTANTS.c413)
    ret1874 = torch.quantize_per_tensor(torch.alias(ret1873), 0.021893126890063286, 129, 13)
    ret1875 = torch.dequantize(torch.alias(ret1874))
    ret1876 = torch.linear(torch.alias(ret1875), torch.dequantize(CONSTANTS.c414))
    ret1877 = torch.add(_923, torch.alias(ret1876))
    _944 = torch.to(torch.alias(ret1877), 6)
    ret1878 = torch.pow(_944, 2)
    ret1879 = torch.mean(torch.alias(ret1878), [-1], True)
    ret1880 = torch.add(torch.alias(ret1879), CONSTANTS.c3)
    ret1881 = torch.rsqrt(torch.alias(ret1880))
    ret1882 = torch.mul(_944, torch.alias(ret1881))
    ret1883 = torch.mul(CONSTANTS.c415, torch.alias(ret1882))
    _945 = torch.alias(ret1883)
    ret1884 = torch.mul(_945, CONSTANTS.c416)
    ret1885 = torch.quantize_per_tensor(torch.alias(ret1884), 0.015351063571870327, 133, 13)
    ret1886 = torch.dequantize(torch.alias(ret1885))
    ret1887 = torch.linear(torch.alias(ret1886), torch.dequantize(CONSTANTS.c417))
    input31 = torch.alias(ret1887)
    ret1888 = torch.silu(input31)
    _946 = torch.alias(ret1888)
    ret1889 = torch.mul(_945, CONSTANTS.c416)
    ret1890 = torch.quantize_per_tensor(torch.alias(ret1889), 0.015351063571870327, 133, 13)
    ret1891 = torch.dequantize(torch.alias(ret1890))
    ret1892 = torch.linear(torch.alias(ret1891), torch.dequantize(CONSTANTS.c418))
    ret1893 = torch.mul(_946, torch.alias(ret1892))
    ret1894 = torch.mul(torch.alias(ret1893), CONSTANTS.c419)
    ret1895 = torch.quantize_per_tensor(torch.alias(ret1894), 0.054621990770101547, 153, 13)
    ret1896 = torch.dequantize(torch.alias(ret1895))
    ret1897 = torch.linear(torch.alias(ret1896), torch.dequantize(CONSTANTS.c420))
    ret1898 = torch.add(_944, torch.alias(ret1897))
    _947 = torch.to(torch.alias(ret1898), 6)
    ret1899 = torch.pow(_947, 2)
    ret1900 = torch.mean(torch.alias(ret1899), [-1], True)
    ret1901 = torch.add(torch.alias(ret1900), CONSTANTS.c3)
    ret1902 = torch.rsqrt(torch.alias(ret1901))
    ret1903 = torch.mul(_947, torch.alias(ret1902))
    ret1904 = torch.mul(CONSTANTS.c421, torch.alias(ret1903))
    ret1905 = torch.mul(torch.alias(ret1904), CONSTANTS.c422)
    ret1906 = torch.quantize_per_tensor(torch.alias(ret1905), 0.030206333845853806, 133, 13)
    ret1907 = torch.dequantize(torch.alias(ret1906))
    ret1908 = torch.linear(torch.alias(ret1907), torch.dequantize(CONSTANTS.c423))
    _948 = torch.alias(ret1908)
    _949 = ((_196, _197, _198, _199), (_220, _221, _222, _223), (_244, _245, _246, _247), (_268, _269, _270, _271), (_292, _293, _294, _295), (_316, _317, _318, _319), (_340, _341, _342, _343), (_364, _365, _366, _367), (_388, _389, _390, _391), (_412, _413, _414, _415), (_436, _437, _438, _439), (_460, _461, _462, _463), (_484, _485, _486, _487), (_508, _509, _510, _511), (_532, _533, _534, _535), (_556, _557, _558, _559), (_580, _581, _582, _583), (_604, _605, _606, _607), (_628, _629, _630, _631), (_652, _653, _654, _655), (_676, _677, _678, _679), (_700, _701, _702, _703), (_724, _725, _726, _727), (_748, _749, _750, _751), (_772, _773, _774, _775), (_796, _797, _798, _799), (_820, _821, _822, _823), (_844, _845, _846, _847), (_868, _869, _870, _871), (_892, _893, _894, _895), (_916, _917, _918, _919), (_940, _941, _942, _943))
    return (_948, _949)
